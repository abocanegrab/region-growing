# Sistema HÃ­brido de DetecciÃ³n de EstrÃ©s Vegetal
## Proyecto Final - VisiÃ³n computacional - MaestrÃ­a en Inteligencia Artificial Aplicada
---

## ğŸ“‹ INFORMACIÃ“N DEL PROYECTO

**MÃ©todo Asignado:** Region Growing  
**Objetivo:**   
**Plazo:** 10 dÃ­as (20 horas/desarrollador)  
**Presupuesto:** $30 USD + RTX 4070 (8GB VRAM) local  

---

## ğŸ¯ PROPUESTA DE VALOR

### InnovaciÃ³n Principal
**Sistema HÃ­brido de SegmentaciÃ³n SemÃ¡ntico-Espectral** que combina:

1. **Region Growing ClÃ¡sico** (baseline) - SegmentaciÃ³n basada en NDVI/NDWI
2. **Region Growing SemÃ¡ntico** (innovaciÃ³n) - SegmentaciÃ³n asistida por Foundation Model (NASA Prithvi)

### Diferenciadores Clave
âœ… **Robustez ante sombras de nubes** - El mÃ©todo semÃ¡ntico ignora variaciones espectrales causadas por sombras  
âœ… **SegmentaciÃ³n consciente de objetos** - Identifica lÃ­mites de campos agrÃ­colas, no solo zonas de estrÃ©s  
âœ… **AnÃ¡lisis jerÃ¡rquico** - Primero segmenta objetos (campos), luego analiza estrÃ©s dentro de cada objeto  
âœ… **ValidaciÃ³n visual directa** - ComparaciÃ³n lado a lado: imagen real vs segmentaciÃ³n  

---

## ğŸ—ï¸ ARQUITECTURA MEJORADA

### Stack TecnolÃ³gico Actualizado

#### Backend: FastAPI (reemplazo de Flask)
**JustificaciÃ³n:**
- âš¡ **Performance**: 3-4x mÃ¡s rÃ¡pido que Flask
- ğŸ“ **DocumentaciÃ³n automÃ¡tica**: OpenAPI/Swagger nativo
- ğŸ”’ **Type safety**: ValidaciÃ³n con Pydantic
- âš™ï¸ **Async nativo**: Ideal para llamadas a Sentinel Hub
- ğŸš€ **ProducciÃ³n-ready**: ASGI, mejor para deployment

```python
# Ejemplo de endpoint FastAPI
from fastapi import FastAPI, BackgroundTasks
from pydantic import BaseModel

class AnalysisRequest(BaseModel):
    bbox: dict
    date_from: str
    date_to: str
    method: str = "hybrid"  # classic | hybrid

@app.post("/api/analysis/analyze")
async def analyze_region(request: AnalysisRequest):
    # Procesamiento asÃ­ncrono
    pass
```


#### Frontend: Nuxt 3 (reemplazo de Vue 3 + Vite)
**JustificaciÃ³n:**
- ğŸ¨ **SSR/SSG**: Mejor SEO y performance inicial
- ğŸ“¦ **Auto-imports**: Menos boilerplate
- ğŸ—‚ï¸ **File-based routing**: Estructura mÃ¡s clara
- ğŸ”§ **MÃ³dulos integrados**: Pinia, composables, layouts
- ğŸ“± **PWA ready**: Instalable como app

```typescript
// Ejemplo de composable Nuxt 3
// composables/useAnalysis.ts
export const useAnalysis = () => {
  const results = useState('analysis-results', () => null)
  const loading = useState('analysis-loading', () => false)
  
  const analyzeRegion = async (bbox: BBox, method: 'classic' | 'hybrid') => {
    loading.value = true
    try {
      const data = await $fetch('/api/analysis/analyze', {
        method: 'POST',
        body: { bbox, method }
      })
      results.value = data
    } finally {
      loading.value = false
    }
  }
  
  return { results, loading, analyzeRegion }
}
```

#### ML/CV Stack
| Componente       | TecnologÃ­a              | VersiÃ³n | Uso                        |
| ---------------- | ----------------------- | ------- | -------------------------- |
| Foundation Model | **Prithvi-EO-1.0-100M** | Latest  | Embeddings semÃ¡nticos      |
| Framework ML     | **PyTorch**             | 2.1+    | Inferencia del modelo      |
| SegmentaciÃ³n     | **MMSegmentation**      | 1.2+    | Pipeline de segmentaciÃ³n   |
| Procesamiento    | **NumPy**               | 1.26+   | Operaciones matriciales    |
| VisiÃ³n           | **OpenCV**              | 4.9+    | Contornos y morfologÃ­a     |
| Geoespacial      | **Rasterio**            | 1.3+    | Manejo de GeoTIFF          |
| GeometrÃ­a        | **Shapely**             | 2.0+    | PolÃ­gonos y simplificaciÃ³n |
| ML Utilities     | **scikit-learn**        | 1.4+    | K-Means clustering         |

#### GestiÃ³n de Dependencias y Entorno

**Backend:**
- **Poetry** - GestiÃ³n moderna de dependencias Python
  - ResoluciÃ³n de dependencias determinÃ­stica
  - Lock file para reproducibilidad
  - Entornos virtuales automÃ¡ticos
  - PublicaciÃ³n simplificada

**Frontend:**
- **pnpm** - Gestor de paquetes eficiente para Node.js
  - MÃ¡s rÃ¡pido que npm/yarn
  - Ahorro de espacio en disco
  - Monorepo-friendly

#### Datos Satelitales
| Fuente             | ResoluciÃ³n | Bandas                          | Uso                                  |
| ------------------ | ---------- | ------------------------------- | ------------------------------------ |
| **Sentinel-2 L2A** | 10m/20m    | **B02,B03,B04,B8A,B11,B12,SCL** | Input Prithvi (6 bandas HLS) + Nubes |
| **Sentinel-2 L2A** | 10m        | B02,B03,B04,B08                 | RGB + NDVI (mÃ©todo clÃ¡sico)          |

**âš ï¸ CRÃTICO - Bandas para Prithvi:**
- Prithvi requiere **6 bandas especÃ­ficas en orden exacto**: B02 (Blue), B03 (Green), B04 (Red), **B8A** (NIR Narrow - 20m), B11 (SWIR1 - 20m), B12 (SWIR2 - 20m)
- **Nota:** B8A es diferente de B08. B8A tiene 20m de resoluciÃ³n y es la banda correcta para HLS
- Todas las bandas deben remuestrearse a resoluciÃ³n comÃºn (10m o 20m) antes de apilar

---

## ğŸ“Š METODOLOGÃA HÃBRIDA DETALLADA

### Pipeline Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USUARIO SELECCIONA ÃREA                       â”‚
â”‚                  (PolÃ­gono en mapa Leaflet)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND: Descarga Sentinel-2 L2A                    â”‚
â”‚  â€¢ Para Prithvi: B02,B03,B04,B8A,B11,B12 (6 bandas HLS)         â”‚
â”‚  â€¢ Para NDVI: B04 (Red), B08 (NIR)                              â”‚
â”‚  â€¢ MÃ¡scara nubes: SCL                                            â”‚
â”‚  â€¢ ResoluciÃ³n: Remuestrear todo a 10m                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                         â”‚
                â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MÃ‰TODO CLÃSICO (RG)     â”‚  â”‚   MÃ‰TODO HÃBRIDO (MGRG)      â”‚
â”‚                           â”‚  â”‚                              â”‚
â”‚ 1. Calcular NDVI          â”‚  â”‚ 1. Preparar HLS (6 bandas)   â”‚
â”‚    (NIR-Red)/(NIR+Red)    â”‚  â”‚    B02,B03,B04,B8A,B11,B12   â”‚
â”‚                           â”‚  â”‚ 2. Remuestrear 20mâ†’10m       â”‚
â”‚                           â”‚  â”‚ 3. Pasar por Prithvi encoder â”‚
â”‚                           â”‚  â”‚ 4. Extraer embeddings (256D) â”‚
â”‚ 2. Generar semillas       â”‚  â”‚ 4. Generar semillas          â”‚
â”‚    (grid 20x20)           â”‚  â”‚    (grid 20x20)              â”‚
â”‚                           â”‚  â”‚                              â”‚
â”‚ 3. Region Growing         â”‚  â”‚ 5. Region Growing SemÃ¡ntico  â”‚
â”‚    Criterio:              â”‚  â”‚    Criterio:                 â”‚
â”‚    |NDVI_A - NDVI_B|      â”‚  â”‚    cosine_sim(emb_A, emb_B)  â”‚
â”‚    < threshold (0.1)      â”‚  â”‚    > threshold (0.85)        â”‚
â”‚                           â”‚  â”‚                              â”‚
â”‚ 4. Clasificar regiones    â”‚  â”‚ 6. Clasificar regiones       â”‚
â”‚    por NDVI:              â”‚  â”‚    por semÃ¡ntica + NDVI:     â”‚
â”‚    â€¢ Alto: <0.3           â”‚  â”‚    â€¢ Primero: lÃ­mite objeto  â”‚
â”‚    â€¢ Medio: 0.3-0.5       â”‚  â”‚    â€¢ Luego: estrÃ©s interno   â”‚
â”‚    â€¢ Bajo: >0.5           â”‚  â”‚                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                             â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  COMPARACIÃ“N A/B VISUAL                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  ClÃ¡sico (RG)        â”‚  â”‚  HÃ­brido (MGRG)      â”‚            â”‚
â”‚  â”‚  â€¢ Sobre-segmenta    â”‚  â”‚  â€¢ Segmenta objetos  â”‚            â”‚
â”‚  â”‚  â€¢ Sensible a sombrasâ”‚  â”‚  â€¢ Robusto a sombras â”‚            â”‚
â”‚  â”‚  â€¢ Fragmentado       â”‚  â”‚  â€¢ Coherente         â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```


### Algoritmo Region Growing ClÃ¡sico (Baseline)

```python
# backend/app/algorithms/classic_region_growing.py
import numpy as np
from typing import List, Tuple

class ClassicRegionGrowing:
    """
    Region Growing clÃ¡sico basado en homogeneidad espectral (NDVI)
    """
    def __init__(self, threshold: float = 0.1, min_size: int = 50):
        self.threshold = threshold
        self.min_size = min_size
    
    def segment(self, ndvi: np.ndarray, seeds: List[Tuple[int, int]]) -> np.ndarray:
        """
        Segmenta imagen NDVI usando Region Growing
        
        Args:
            ndvi: Array 2D con valores NDVI [-1, 1]
            seeds: Lista de coordenadas (y, x) de semillas
            
        Returns:
            labeled_image: Array 2D con etiquetas de regiÃ³n
        """
        h, w = ndvi.shape
        labeled = np.zeros((h, w), dtype=np.int32)
        region_id = 1
        
        for seed_y, seed_x in seeds:
            if labeled[seed_y, seed_x] != 0:
                continue
                
            # Valor de referencia de la semilla
            seed_value = ndvi[seed_y, seed_x]
            
            # BFS para crecer regiÃ³n
            queue = [(seed_y, seed_x)]
            region_pixels = []
            
            while queue:
                y, x = queue.pop(0)
                
                # Verificar lÃ­mites y si ya fue visitado
                if not (0 <= y < h and 0 <= x < w):
                    continue
                if labeled[y, x] != 0:
                    continue
                
                # Criterio de homogeneidad espectral
                pixel_value = ndvi[y, x]
                if abs(pixel_value - seed_value) <= self.threshold:
                    labeled[y, x] = region_id
                    region_pixels.append((y, x))
                    
                    # Agregar vecinos (4-conectividad)
                    queue.extend([
                        (y-1, x), (y+1, x),
                        (y, x-1), (y, x+1)
                    ])
            
            # Filtrar regiones pequeÃ±as (ruido)
            if len(region_pixels) >= self.min_size:
                region_id += 1
            else:
                for y, x in region_pixels:
                    labeled[y, x] = 0
        
        return labeled
    
    def classify_stress(self, ndvi: np.ndarray, labeled: np.ndarray) -> dict:
        """
        Clasifica regiones por nivel de estrÃ©s vegetal
        """
        regions = {}
        for region_id in np.unique(labeled):
            if region_id == 0:
                continue
            
            mask = labeled == region_id
            region_ndvi = ndvi[mask]
            mean_ndvi = np.mean(region_ndvi)
            
            # ClasificaciÃ³n de estrÃ©s
            if mean_ndvi < 0.3:
                stress = "high"
            elif mean_ndvi < 0.5:
                stress = "medium"
            else:
                stress = "low"
            
            regions[region_id] = {
                "mean_ndvi": float(mean_ndvi),
                "std_ndvi": float(np.std(region_ndvi)),
                "size": int(np.sum(mask)),
                "stress_level": stress
            }
        
        return regions
```


### Algoritmo Region Growing SemÃ¡ntico (InnovaciÃ³n)

```python
# backend/app/algorithms/semantic_region_growing.py
import torch
import numpy as np
from typing import List, Tuple
from sklearn.metrics.pairwise import cosine_similarity

class SemanticRegionGrowing:
    """
    Region Growing semÃ¡ntico basado en embeddings de Foundation Model
    Inspirado en CRGNet (Ghamisi et al., 2022)
    """
    def __init__(
        self, 
        model,  # Prithvi encoder
        threshold: float = 0.85,  # Similitud coseno
        min_size: int = 50
    ):
        self.model = model
        self.threshold = threshold
        self.min_size = min_size
    
    def extract_embeddings(self, image: np.ndarray) -> np.ndarray:
        """
        Extrae embeddings semÃ¡nticos usando Prithvi
        
        Args:
            image: Array (H, W, 6) con bandas HLS en orden:
                   [B02, B03, B04, B8A, B11, B12]
                   âš ï¸ CRÃTICO: B8A (no B08), todas a 10m resoluciÃ³n
            
        Returns:
            embeddings: Array (H, W, 256) con features semÃ¡nticos
        """
        # Convertir a tensor y normalizar
        x = torch.from_numpy(image).permute(2, 0, 1).unsqueeze(0).float()
        x = (x - x.mean()) / (x.std() + 1e-8)
        
        # Inferencia (solo encoder, sin decoder)
        with torch.no_grad():
            features = self.model.encode(x)  # (1, 256, H', W')
        
        # Interpolar a resoluciÃ³n original si es necesario
        if features.shape[2:] != image.shape[:2]:
            features = torch.nn.functional.interpolate(
                features, 
                size=image.shape[:2], 
                mode='bilinear'
            )
        
        # Convertir a numpy (H, W, 256)
        embeddings = features.squeeze(0).permute(1, 2, 0).cpu().numpy()
        
        # Normalizar embeddings (importante para cosine similarity)
        norms = np.linalg.norm(embeddings, axis=2, keepdims=True)
        embeddings = embeddings / (norms + 1e-8)
        
        return embeddings
    
    def generate_smart_seeds(
        self, 
        embeddings: np.ndarray, 
        n_clusters: int = 5
    ) -> List[Tuple[int, int]]:
        """
        ğŸ†• MEJORA: Genera semillas inteligentes usando K-Means sobre embeddings
        
        En lugar de un grid fijo, encuentra los pÃ­xeles mÃ¡s representativos
        de cada clase semÃ¡ntica (cultivo, agua, bosque, etc.)
        
        Args:
            embeddings: Array (H, W, 256) con features semÃ¡nticos
            n_clusters: NÃºmero de clusters (clases semÃ¡nticas esperadas)
            
        Returns:
            seeds: Lista de coordenadas (y, x) de centroides
        """
        from sklearn.cluster import KMeans
        
        h, w, d = embeddings.shape
        
        # Reshape para K-Means: (H*W, 256)
        emb_flat = embeddings.reshape(-1, d)
        
        # Clustering
        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
        labels = kmeans.fit_predict(emb_flat)
        
        # Encontrar pÃ­xel mÃ¡s cercano a cada centroide
        seeds = []
        for cluster_id in range(n_clusters):
            # MÃ¡scara de pÃ­xeles en este cluster
            cluster_mask = (labels == cluster_id)
            cluster_embeddings = emb_flat[cluster_mask]
            
            # Centroide del cluster
            centroid = kmeans.cluster_centers_[cluster_id]
            
            # Encontrar pÃ­xel mÃ¡s cercano al centroide
            distances = np.linalg.norm(cluster_embeddings - centroid, axis=1)
            closest_idx = np.argmin(distances)
            
            # Convertir Ã­ndice flat a coordenadas (y, x)
            cluster_indices = np.where(cluster_mask)[0]
            flat_idx = cluster_indices[closest_idx]
            y, x = divmod(flat_idx, w)
            
            seeds.append((y, x))
        
        return seeds
    
    def segment(
        self, 
        embeddings: np.ndarray, 
        seeds: List[Tuple[int, int]] = None,
        use_smart_seeds: bool = True
    ) -> np.ndarray:
        """
        Segmenta usando similitud semÃ¡ntica en espacio de embeddings
        
        Args:
            embeddings: Array (H, W, 256)
            seeds: Lista de semillas (opcional si use_smart_seeds=True)
            use_smart_seeds: Si True, genera semillas con K-Means
        """
        h, w, d = embeddings.shape
        labeled = np.zeros((h, w), dtype=np.int32)
        region_id = 1
        
        # ğŸ†• Generar semillas inteligentes si no se proporcionan
        if seeds is None or use_smart_seeds:
            seeds = self.generate_smart_seeds(embeddings, n_clusters=5)
            print(f"âœ… Semillas inteligentes generadas: {len(seeds)} clusters")
        
        for seed_y, seed_x in seeds:
            if labeled[seed_y, seed_x] != 0:
                continue
            
            # Embedding de referencia
            seed_emb = embeddings[seed_y, seed_x]
            
            # BFS para crecer regiÃ³n
            queue = [(seed_y, seed_x)]
            region_pixels = []
            
            while queue:
                y, x = queue.pop(0)
                
                if not (0 <= y < h and 0 <= x < w):
                    continue
                if labeled[y, x] != 0:
                    continue
                
                # Criterio de homogeneidad SEMÃNTICA
                pixel_emb = embeddings[y, x]
                similarity = np.dot(seed_emb, pixel_emb)  # Ya normalizados
                
                if similarity >= self.threshold:
                    labeled[y, x] = region_id
                    region_pixels.append((y, x))
                    
                    # Agregar vecinos
                    queue.extend([
                        (y-1, x), (y+1, x),
                        (y, x-1), (y, x+1)
                    ])
            
            # Filtrar regiones pequeÃ±as
            if len(region_pixels) >= self.min_size:
                region_id += 1
            else:
                for y, x in region_pixels:
                    labeled[y, x] = 0
        
        return labeled
    
    def analyze_stress_within_objects(
        self, 
        ndvi: np.ndarray, 
        semantic_labels: np.ndarray
    ) -> dict:
        """
        AnÃ¡lisis jerÃ¡rquico: primero objetos, luego estrÃ©s interno
        """
        results = {}
        
        for obj_id in np.unique(semantic_labels):
            if obj_id == 0:
                continue
            
            # MÃ¡scara del objeto semÃ¡ntico
            obj_mask = semantic_labels == obj_id
            obj_ndvi = ndvi[obj_mask]
            
            # EstadÃ­sticas del objeto completo
            mean_ndvi = np.mean(obj_ndvi)
            
            # Sub-segmentaciÃ³n por estrÃ©s dentro del objeto
            stress_zones = {
                "high": np.sum(obj_ndvi < 0.3),
                "medium": np.sum((obj_ndvi >= 0.3) & (obj_ndvi < 0.5)),
                "low": np.sum(obj_ndvi >= 0.5)
            }
            
            results[obj_id] = {
                "mean_ndvi": float(mean_ndvi),
                "size": int(np.sum(obj_mask)),
                "stress_distribution": stress_zones,
                "dominant_stress": max(stress_zones, key=stress_zones.get)
            }
        
        return results
```


---

## ğŸ“ˆ PLAN DE TRABAJO SCRUM (10 DÃAS)

### Sprint Backlog Detallado

#### **Ã‰pica 1: FundaciÃ³n y Baseline (DÃ­as 1-3)**

### US-1: Migrar backend de Flask a FastAPI + Poetry

- **Como** desarrollador
- **Quiero** migrar el backend de Flask a FastAPI y configurar Poetry
- **Para que** tengamos mejor performance, documentaciÃ³n automÃ¡tica y gestiÃ³n de dependencias moderna

**Criterios de AceptaciÃ³n:**
- âœ… **Poetry configurado** como gestor de dependencias
  - `pyproject.toml` creado con metadatos del proyecto
  - `poetry.lock` para reproducibilidad
  - Entorno virtual automÃ¡tico
- âœ… Endpoints REST funcionando correctamente
- âœ… Swagger docs automÃ¡tico generado (`/api/docs`)
- âœ… ValidaciÃ³n con Pydantic implementada
- âœ… CORS configurado para Nuxt 3
- âœ… Estructura de proyecto limpia (app/, config/, tests/)

**CÃ³digo Esperado:**
```bash
# Inicializar Poetry
poetry init
poetry add fastapi uvicorn[standard] pydantic pydantic-settings
poetry add --group dev pytest black ruff

# Ejecutar
poetry run uvicorn app.main:app --reload
```

```toml
# pyproject.toml
[tool.poetry]
name = "vision-backend"
version = "1.0.0"
description = "Sistema HÃ­brido de DetecciÃ³n de EstrÃ©s Vegetal"

[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.109.0"
uvicorn = {extras = ["standard"], version = "^0.27.0"}
pydantic = "^2.5.0"
torch = "^2.1.2"
numpy = "^1.26.3"
opencv-python = "^4.9.0"
scikit-learn = "^1.4.0"
sentinelhub = "^3.10.2"

[tool.poetry.group.dev.dependencies]
pytest = "^7.4.0"
black = "^23.12.0"
ruff = "^0.1.9"
```

**EstimaciÃ³n:** 4 horas  
**Responsable:** Carlos Bocanegra  
**Estado:** â³ Pendiente

---

### US-2: Migrar frontend de Vue+Vite a Nuxt 3

- **Como** desarrollador
- **Quiero** migrar el frontend de Vue+Vite a Nuxt 3
- **Para que** tengamos SSR y mejor estructura de proyecto

**Criterios de AceptaciÃ³n:**
- âœ… SSR configurado y funcionando
- âœ… Auto-imports funcionando (componentes, composables)
- âœ… Composables creados (useAnalysis, useMap)
- âœ… Pinia store configurado
- âœ… Leaflet integrado

**EstimaciÃ³n:** 6 horas  
**Responsable:** Luis VÃ¡zquez  
**Estado:** â³ Pendiente

---

### US-3: Descargar imÃ¡genes Sentinel-2

- **Como** usuario
- **Quiero** que el sistema descargue imÃ¡genes Sentinel-2 automÃ¡ticamente
- **Para que** pueda analizar cualquier regiÃ³n del mundo

**Criterios de AceptaciÃ³n:**
- âœ… IntegraciÃ³n con Sentinel Hub API funcionando
- âœ… Descarga de bandas RGB (B02, B03, B04)
- âœ… Descarga de banda NIR (B08) para NDVI
- âœ… Descarga de banda SCL para mÃ¡scara de nubes
- âœ… Manejo de errores (Ã¡rea muy grande, sin datos, etc.)

**EstimaciÃ³n:** 4 horas  
**Responsable:** Carlos Bocanegra  
**Estado:** âœ… Completado

---

### US-4: Implementar Region Growing clÃ¡sico

- **Como** investigador
- **Quiero** implementar el algoritmo Region Growing clÃ¡sico
- **Para que** tengamos la lÃ­nea base de comparaciÃ³n

**Criterios de AceptaciÃ³n:**
- âœ… Algoritmo funcional con BFS (4-conectividad)
- âœ… SegmentaciÃ³n basada en NDVI
- âœ… Criterio de homogeneidad: |NDVI_A - NDVI_B| < threshold
- âœ… ClasificaciÃ³n de estrÃ©s (alto/medio/bajo)
- âœ… Filtrado de regiones pequeÃ±as (ruido)

**EstimaciÃ³n:** 6 horas  
**Responsable:** Carlos Bocanegra  
**Estado:** âœ… Completado

---

**Entregable DÃ­a 3:** Backend FastAPI + Frontend Nuxt 3 + RG ClÃ¡sico funcional

---

#### **Ã‰pica 2: InnovaciÃ³n SOTA (DÃ­as 4-7)**

### US-5: Descargar y configurar Prithvi

- **Como** investigador
- **Quiero** descargar y configurar el modelo Prithvi
- **Para que** podamos extraer embeddings semÃ¡nticos

**Criterios de AceptaciÃ³n:**
- âœ… Modelo Prithvi-EO-1.0-100M descargado de HuggingFace
- âœ… Dependencias instaladas (PyTorch, MMSegmentation, timm)
- âœ… Test de inferencia exitoso con imagen de ejemplo
- âœ… Verificar que corre en RTX 4070 (8GB VRAM)

**EstimaciÃ³n:** 4 horas  
**Responsable:** Arthur Zizumbo  
**Estado:** â³ Pendiente

---

### US-6: Extraer embeddings de imÃ¡genes Sentinel-2

- **Como** desarrollador
- **Quiero** extraer embeddings semÃ¡nticos de imÃ¡genes Sentinel-2
- **Para que** podamos usar el mÃ©todo MGRG

**âš ï¸ CRÃTICO - Bandas Correctas para Prithvi:**

Prithvi-EO-1.0-100M fue pre-entrenado en formato HLS y requiere **exactamente 6 bandas en orden especÃ­fico**:

1. **B02** - Blue (490 nm) - 10m
2. **B03** - Green (560 nm) - 10m
3. **B04** - Red (665 nm) - 10m
4. **B8A** - NIR Narrow (865 nm) - **20m** âš ï¸ (NO es B08)
5. **B11** - SWIR1 (1610 nm) - **20m**
6. **B12** - SWIR2 (2190 nm) - **20m**

**Diferencia crÃ­tica:** B08 (NIR Broad, 10m) â‰  B8A (NIR Narrow, 20m). Prithvi espera B8A.

**Criterios de AceptaciÃ³n:**
- âœ… Descargar bandas correctas: B02, B03, B04, **B8A**, B11, B12
- âœ… Remuestrear B8A, B11, B12 de 20m â†’ 10m usando interpolaciÃ³n bilineal
- âœ… Apilar en orden exacto: [B02, B03, B04, B8A, B11, B12] (6 canales)
- âœ… Normalizar imagen (mean=0, std=1)
- âœ… Inferencia con Prithvi (solo encoder, sin decoder)
- âœ… Obtener embeddings con shape (H, W, 256)
- âœ… Normalizar embeddings (L2 norm) para cosine similarity

**CÃ³digo Esperado:**
```python
# Evalscript para Sentinel Hub
evalscript = """
//VERSION=3
function setup() {
    return {
        input: [{
            bands: ["B02", "B03", "B04", "B8A", "B11", "B12"],
            units: "REFLECTANCE"
        }],
        output: { bands: 6, sampleType: "FLOAT32" }
    };
}
function evaluatePixel(sample) {
    return [sample.B02, sample.B03, sample.B04, 
            sample.B8A, sample.B11, sample.B12];
}
"""

# Remuestreo de bandas 20m â†’ 10m
from scipy.ndimage import zoom
b8a_10m = zoom(b8a_20m, 2, order=1)  # Bilinear
b11_10m = zoom(b11_20m, 2, order=1)
b12_10m = zoom(b12_20m, 2, order=1)

# Apilar en orden correcto
hls_image = np.stack([b02, b03, b04, b8a_10m, b11_10m, b12_10m], axis=-1)
```

**Referencias:**
- Prithvi HuggingFace: https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-1.0-100M
- HLS Product Guide: https://lpdaac.usgs.gov/documents/1698/HLS_User_Guide_V2.pdf

**EstimaciÃ³n:** 10 horas  
**Responsables:** Arthur Zizumbo + Luis VÃ¡zquez  
**Estado:** â³ Pendiente

---

### US-7: Implementar MGRG (Region Growing SemÃ¡ntico)

- **Como** desarrollador
- **Quiero** implementar el algoritmo MGRG (Metric-Guided Region Growing)
- **Para que** tengamos segmentaciÃ³n semÃ¡ntica robusta

**ğŸŸ¡ MEJORA RECOMENDADA - Semillas Inteligentes:**

En lugar de un grid fijo (20x20), usar **K-Means clustering** sobre embeddings para encontrar semillas mÃ¡s representativas.

**Ventajas:**
- Semillas "semÃ¡nticamente puras" (centroide de cada cluster)
- MÃ¡s robusto que grid aleatorio
- Demuestra integraciÃ³n avanzada de IA
- Reduce sobre-segmentaciÃ³n

**Criterios de AceptaciÃ³n:**
- âœ… Algoritmo funcional con BFS (4-conectividad) sobre embeddings
- âœ… Criterio de homogeneidad: cosine_similarity(emb_A, emb_B) > threshold
- âœ… Threshold optimizado (0.85 por defecto)
- âœ… **MÃ©todo `generate_smart_seeds()` implementado** con K-Means (K=5-10)
- âœ… ComparaciÃ³n: grid fijo vs K-Means inteligente
- âœ… Filtrado de regiones pequeÃ±as (min_size=50)

**CÃ³digo Esperado:**
```python
from sklearn.cluster import KMeans

def generate_smart_seeds(embeddings, n_clusters=5):
    """Genera semillas usando K-Means sobre embeddings"""
    h, w, d = embeddings.shape
    emb_flat = embeddings.reshape(-1, d)
    
    # Clustering
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    labels = kmeans.fit_predict(emb_flat)
    
    # Encontrar pÃ­xel mÃ¡s cercano a cada centroide
    seeds = []
    for i in range(n_clusters):
        cluster_mask = (labels == i)
        cluster_embs = emb_flat[cluster_mask]
        centroid = kmeans.cluster_centers_[i]
        
        distances = np.linalg.norm(cluster_embs - centroid, axis=1)
        closest_idx = np.argmin(distances)
        
        flat_idx = np.where(cluster_mask)[0][closest_idx]
        y, x = divmod(flat_idx, w)
        seeds.append((y, x))
    
    return seeds
```

**ComparaciÃ³n esperada:**

| MÃ©todo | Grid Fijo | K-Means Inteligente |
|--------|-----------|---------------------|
| Semillas | ~400 | 5-10 |
| Calidad | Aleatorio | Representativo |
| Sobre-segmentaciÃ³n | Alta | Baja |
| Tiempo | RÃ¡pido | +2-3 seg |

**EstimaciÃ³n:** 12 horas  
**Responsables:** Carlos Bocanegra + Arthur Zizumbo  
**Estado:** â³ Pendiente

---

### US-8: Generar comparativa A/B visual

- **Como** investigador
- **Quiero** generar una comparativa visual lado a lado
- **Para que** podamos demostrar la superioridad del mÃ©todo hÃ­brido

**Criterios de AceptaciÃ³n:**
- âœ… Misma imagen procesada por ambos mÃ©todos (RG ClÃ¡sico + MGRG)
- âœ… VisualizaciÃ³n lado a lado en frontend
- âœ… MÃ©tricas cuantitativas calculadas:
  - Coherencia espacial
  - NÃºmero de regiones
  - PrecisiÃ³n de lÃ­mites (si hay ground truth)
- âœ… Caso de fallo claro (ej: campo con sombra de nube)
- âœ… Exportar imÃ¡genes en alta resoluciÃ³n (300 DPI)

**EstimaciÃ³n:** 6 horas  
**Responsable:** Luis VÃ¡zquez  
**Estado:** â³ Pendiente

---

### US-9: Implementar anÃ¡lisis jerÃ¡rquico

- **Como** usuario
- **Quiero** ver anÃ¡lisis jerÃ¡rquico (objeto â†’ estrÃ©s)
- **Para que** pueda entender quÃ© objeto tiene estrÃ©s y cuÃ¡nto

**Criterios de AceptaciÃ³n:**
- âœ… Primero: segmentaciÃ³n semÃ¡ntica (identificar objetos)
- âœ… Luego: anÃ¡lisis NDVI interno de cada objeto
- âœ… Reporte estructurado por objeto:
  - ID del objeto
  - NDVI promedio
  - DistribuciÃ³n de estrÃ©s interno (alto/medio/bajo)
  - Ãrea en hectÃ¡reas
- âœ… VisualizaciÃ³n con colores por estrÃ©s interno

**EstimaciÃ³n:** 4 horas  
**Responsable:** Carlos Bocanegra  
**Estado:** â³ Pendiente

---

**Entregable DÃ­a 7:** Sistema hÃ­brido completo con comparativa A/B

---


---

## ğŸ“š REFERENCIAS ACADÃ‰MICAS ACTUALIZADAS (2022-2025)

### Referencias Principales (CitaciÃ³n Obligatoria)

1. **Ma, L., Yan, Z., Li, M., Liu, T., Tan, L., Wang, X., He, W., Wang, R., He, G., Lu, H., & Blaschke, T. (2024).** Deep learning meets object-based image analysis: Tasks, challenges, strategies, and perspectives. *IEEE Geoscience and Remote Sensing Magazine*, 1â€“29. https://doi.org/10.1109/MGRS.2024.3489952
   - **Relevancia:** Marco teÃ³rico completo sobre hibridaciÃ³n DL-OBIA, base conceptual del proyecto

2. **Jakubik, J., Roy, S., Phillips, C. E., Fraccaro, P., Godwin, D., Zadrozny, B., Szwarcman, D., Gomes, C., Nyirjesy, G., Edwards, B., Kimura, D., Simumba, N., Chu, L., Mukkavilli, S. K., Lambhate, D., Das, K., Bangalore Ravi, S. N., Oliveira, D., Muszynski, G., ... Schmude, J. (2024).** Foundation models for generalist geospatial artificial intelligence. *arXiv preprint arXiv:2310.18660v2*. https://arxiv.org/abs/2310.18660
   - **Relevancia:** Paper oficial de Prithvi (NASA/IBM), justifica uso de Foundation Models

3. **Ghamisi, P., Rasti, B., Yokoya, N., Wang, Q., Hofle, B., Bruzzone, L., Bovolo, F., Chi, M., Anders, K., Gloaguen, R., Atkinson, P. M., & Benediktsson, J. A. (2022).** Consistency-regularized region-growing network for semantic segmentation of urban scenes with point-level annotations. *IEEE Transactions on Image Processing*, 31, 5038â€“5051. https://doi.org/10.1109/TIP.2022.3188339
   - **Relevancia:** CRGNet, inspiraciÃ³n directa para MGRG (Metric-Guided Region Growing)

4. **Yang, T., Zou, Y., Yang, X., & del Rey Castillo, E. (2024).** Domain knowledge-enhanced region growing framework for semantic segmentation of bridge point clouds. *Automation in Construction*, 164, 105572. https://doi.org/10.1016/j.autcon.2024.105572
   - **Relevancia:** Region Growing con conocimiento semÃ¡ntico, aplicaciÃ³n reciente

5. **Cong, Y., Khanna, S., Meng, C., Liu, P., Rozi, E., He, Y., Burke, M., Lobell, D. B., & Ermon, S. (2022).** SatMAE: Pre-training transformers for temporal and multi-spectral satellite imagery. *Advances in Neural Information Processing Systems*, 35, 197â€“211. https://proceedings.neurips.cc/paper_files/paper/2022/hash/01c561df365429f33fcd7a7faa44c985-Abstract-Conference.html
   - **Relevancia:** Masked Autoencoders para imÃ¡genes satelitales, alternativa a Prithvi

## Referencias TÃ©cnicas (ImplementaciÃ³n)

11. **IBM & NASA. (2023).** Prithvi-EO-1.0-100M: Pretrained foundation model for harmonized Landsat Sentinel-2 (HLS). *Hugging Face Model Hub*. https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-1.0-100M
    - **Relevancia:** Modelo pre-entrenado usado en el proyecto
    - **âš ï¸ CRÃTICO:** Requiere 6 bandas HLS: B02, B03, B04, B8A, B11, B12 (ver documentaciÃ³n del modelo)

11b. **Claverie, M., Ju, J., Masek, J. G., Dungan, J. L., Vermote, E. F., Roger, J. C., Skakun, S. V., & Justice, C. (2018).** The Harmonized Landsat and Sentinel-2 surface reflectance data set. *Remote Sensing of Environment*, 219, 145â€“161. https://doi.org/10.1016/j.rse.2018.09.002
    - **Relevancia:** EspecificaciÃ³n tÃ©cnica del formato HLS, bandas y preprocesamiento

12. **Drusch, M., Del Bello, U., Carlier, S., Colin, O., Fernandez, V., Gascon, F., Hoersch, B., Isola, C., Laberinti, P., Martimort, P., Meygret, A., Spoto, F., Sy, O., Marchese, F., & Bargellini, P. (2012).** Sentinel-2: ESA's optical high-resolution mission for GMES operational services. *Remote Sensing of Environment*, 120, 25â€“36. https://doi.org/10.1016/j.rse.2011.11.026
    - **Relevancia:** Paper oficial de Sentinel-2, descripciÃ³n tÃ©cnica de las bandas

13. **Tucker, C. J. (1979).** Red and photographic infrared linear combinations for monitoring vegetation. *Remote Sensing of Environment*, 8(2), 127â€“150. https://doi.org/10.1016/0034-4257(79)90013-0
    - **Relevancia:** Paper original del NDVI, citaciÃ³n clÃ¡sica obligatoria

14. **Gao, B. C. (1996).** NDWIâ€”A normalized difference water index for remote sensing of vegetation liquid water from space. *Remote Sensing of Environment*, 58(3), 257â€“266. https://doi.org/10.1016/S0034-4257(96)00067-3
    - **Relevancia:** Paper original del NDWI, Ã­ndice de estrÃ©s hÃ­drico

15. **Chen, K., Zou, Z., & Shi, Z. (2021).** Building extraction from remote sensing images with sparse token transformers. *Remote Sensing*, 13(21), 4441. https://doi.org/10.3390/rs13214441
    - **Relevancia:** Transformers para segmentaciÃ³n, arquitectura moderna


---

## ğŸ’» IMPLEMENTACIÃ“N TÃ‰CNICA DETALLADA

### Estructura del Proyecto Mejorada

```
proyecto-vision-computacional/
â”‚
â”œâ”€â”€ backend/                                    # FastAPI Backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                            # FastAPI app con CORS
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ analysis.py                # Endpoints de anÃ¡lisis
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ health.py                  # Health checks
â”‚   â”‚   â”‚   â””â”€â”€ schemas/
â”‚   â”‚   â”‚       â”œâ”€â”€ requests.py                # Pydantic request models
â”‚   â”‚   â”‚       â””â”€â”€ responses.py               # Pydantic response models
â”‚   â”‚   â”œâ”€â”€ algorithms/
â”‚   â”‚   â”‚   â”œâ”€â”€ classic_region_growing.py      # RG ClÃ¡sico
â”‚   â”‚   â”‚   â””â”€â”€ semantic_region_growing.py     # MGRG (innovaciÃ³n)
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ sentinel_hub.py                # Descarga Sentinel-2
â”‚   â”‚   â”‚   â”œâ”€â”€ prithvi_inference.py           # Inferencia Prithvi
â”‚   â”‚   â”‚   â”œâ”€â”€ ndvi_calculator.py             # CÃ¡lculo Ã­ndices
â”‚   â”‚   â”‚   â””â”€â”€ geo_converter.py               # ConversiÃ³n geoespacial
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â””â”€â”€ prithvi_loader.py              # Carga modelo Prithvi
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â”œâ”€â”€ test_classic_rg.py
â”‚   â”‚   â””â”€â”€ test_semantic_rg.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ frontend/                                   # Nuxt 3 Frontend
â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â””â”€â”€ index.vue                          # PÃ¡gina principal
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ Map/
â”‚   â”‚   â”‚   â”œâ”€â”€ LeafletMap.vue                 # Mapa interactivo
â”‚   â”‚   â”‚   â””â”€â”€ DrawControl.vue                # Control de dibujo
â”‚   â”‚   â”œâ”€â”€ Analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ MethodSelector.vue             # Selector Classic/Hybrid
â”‚   â”‚   â”‚   â”œâ”€â”€ ComparisonView.vue             # Vista A/B
â”‚   â”‚   â”‚   â””â”€â”€ ResultsPanel.vue               # Panel de resultados
â”‚   â”‚   â””â”€â”€ Common/
â”‚   â”‚       â”œâ”€â”€ LoadingSpinner.vue
â”‚   â”‚       â””â”€â”€ ErrorAlert.vue
â”‚   â”œâ”€â”€ composables/
â”‚   â”‚   â”œâ”€â”€ useAnalysis.ts                     # LÃ³gica de anÃ¡lisis
â”‚   â”‚   â”œâ”€â”€ useMap.ts                          # LÃ³gica del mapa
â”‚   â”‚   â””â”€â”€ usePrithvi.ts                      # Estado Prithvi
â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â””â”€â”€ analysis.ts                        # Pinia store
â”‚   â”œâ”€â”€ nuxt.config.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ notebooks/                                  # Google Colab
â”‚   â”œâ”€â”€ Region_Growing_Comparison.ipynb        # Notebook principal
â”‚   â””â”€â”€ assets/
â”‚       â”œâ”€â”€ example_images/                    # ImÃ¡genes de ejemplo
â”‚       â””â”€â”€ results/                           # Resultados guardados
â”‚
â”œâ”€â”€ docs/                                       # DocumentaciÃ³n
â”‚   â”œâ”€â”€ articulo_cientifico.pdf                # ArtÃ­culo final
â”‚   â”œâ”€â”€ presentacion.pptx                      # PresentaciÃ³n clase
â”‚   â””â”€â”€ video_tutorial.mp4                     # Video 5-10 min
â”‚
â””â”€â”€ README.md                                   # DocumentaciÃ³n principal
```

### ConfiguraciÃ³n del Entorno

#### Backend (FastAPI)

```bash
# requirements.txt
fastapi==0.109.0
uvicorn[standard]==0.27.0
pydantic==2.5.0
pydantic-settings==2.1.0

# ML/CV
torch==2.1.2
torchvision==0.16.2
mmsegmentation==1.2.2
timm==0.9.12

# Procesamiento
numpy==1.26.3
opencv-python==4.9.0.80
scikit-image==0.22.0
scikit-learn==1.4.0

# Geoespacial
rasterio==1.3.9
shapely==2.0.2
pyproj==3.6.1
geojson==3.1.0

# Sentinel Hub
sentinelhub==3.10.2

# Utilidades
python-dotenv==1.0.0
pillow==10.2.0
```

```python
# backend/app/main.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from app.api.routes import analysis, health

app = FastAPI(
    title="Sistema HÃ­brido de DetecciÃ³n de EstrÃ©s Vegetal",
    description="API para comparaciÃ³n de Region Growing ClÃ¡sico vs SemÃ¡ntico",
    version="2.0.0",
    docs_url="/api/docs",
    redoc_url="/api/redoc"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Nuxt dev server
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Routers
app.include_router(health.router, prefix="/api", tags=["Health"])
app.include_router(analysis.router, prefix="/api/analysis", tags=["Analysis"])

@app.on_event("startup")
async def startup_event():
    """Cargar modelo Prithvi al iniciar"""
    from app.models.prithvi_loader import load_prithvi_model
    app.state.prithvi_model = load_prithvi_model()
    print("âœ… Modelo Prithvi cargado exitosamente")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=True)
```


#### Frontend (Nuxt 3)

```bash
# package.json dependencies
{
  "dependencies": {
    "nuxt": "^3.10.0",
    "@pinia/nuxt": "^0.5.1",
    "leaflet": "^1.9.4",
    "@vueuse/core": "^10.7.2",
    "axios": "^1.6.5"
  },
  "devDependencies": {
    "@nuxtjs/tailwindcss": "^6.11.4",
    "typescript": "^5.3.3"
  }
}
```

```typescript
// nuxt.config.ts
export default defineNuxtConfig({
  modules: [
    '@pinia/nuxt',
    '@nuxtjs/tailwindcss'
  ],
  
  runtimeConfig: {
    public: {
      apiBase: process.env.NUXT_PUBLIC_API_BASE || 'http://localhost:8000'
    }
  },
  
  app: {
    head: {
      title: 'Sistema HÃ­brido de DetecciÃ³n de EstrÃ©s Vegetal',
      meta: [
        { charset: 'utf-8' },
        { name: 'viewport', content: 'width=device-width, initial-scale=1' },
        { 
          name: 'description', 
          content: 'ComparaciÃ³n de Region Growing ClÃ¡sico vs SemÃ¡ntico para anÃ¡lisis de vegetaciÃ³n' 
        }
      ],
      link: [
        { 
          rel: 'stylesheet', 
          href: 'https://unpkg.com/leaflet@1.9.4/dist/leaflet.css' 
        }
      ]
    }
  },
  
  ssr: true,  // Server-Side Rendering habilitado
  
  typescript: {
    strict: true,
    typeCheck: true
  }
})
```

```typescript
// composables/useAnalysis.ts
import type { BBox, AnalysisMethod, AnalysisResult } from '~/types'

export const useAnalysis = () => {
  const config = useRuntimeConfig()
  const results = useState<AnalysisResult | null>('analysis-results', () => null)
  const loading = useState<boolean>('analysis-loading', () => false)
  const error = useState<string | null>('analysis-error', () => null)
  
  const analyzeRegion = async (
    bbox: BBox, 
    method: AnalysisMethod = 'hybrid',
    dateFrom?: string,
    dateTo?: string
  ) => {
    loading.value = true
    error.value = null
    
    try {
      const response = await $fetch<AnalysisResult>(
        `${config.public.apiBase}/api/analysis/analyze`,
        {
          method: 'POST',
          body: {
            bbox,
            method,
            date_from: dateFrom,
            date_to: dateTo
          }
        }
      )
      
      results.value = response
      return response
    } catch (e: any) {
      error.value = e.message || 'Error al analizar regiÃ³n'
      throw e
    } finally {
      loading.value = false
    }
  }
  
  const compareMethodsAB = async (bbox: BBox) => {
    // Ejecutar ambos mÃ©todos en paralelo
    const [classicResult, hybridResult] = await Promise.all([
      analyzeRegion(bbox, 'classic'),
      analyzeRegion(bbox, 'hybrid')
    ])
    
    return {
      classic: classicResult,
      hybrid: hybridResult,
      comparison: {
        coherence: calculateCoherence(classicResult, hybridResult),
        regionCount: {
          classic: classicResult.statistics.num_regions,
          hybrid: hybridResult.statistics.num_regions
        }
      }
    }
  }
  
  return {
    results: readonly(results),
    loading: readonly(loading),
    error: readonly(error),
    analyzeRegion,
    compareMethodsAB
  }
}

function calculateCoherence(classic: any, hybrid: any): number {
  // MÃ©trica de coherencia espacial (simplificada)
  const classicFragmentation = classic.statistics.num_regions / classic.statistics.total_area
  const hybridFragmentation = hybrid.statistics.num_regions / hybrid.statistics.total_area
  
  return (1 - hybridFragmentation / classicFragmentation) * 100
}
```

---

## ğŸ“ CONCLUSIÃ“N

Este proyecto estÃ¡ diseÃ±ado para obtener **100/100 puntos** cumpliendo con excelencia todos los criterios de la rÃºbrica:

### Fortalezas del Proyecto

1. **InnovaciÃ³n Real:** No es solo implementar Region Growing, sino compararlo con un mÃ©todo SOTA usando Foundation Models

2. **Viabilidad TÃ©cnica:** Todo es factible en 10 dÃ­as con los recursos disponibles (RTX 4070 + $30 USD)

3. **Impacto AcadÃ©mico:** ContribuciÃ³n clara al estado del arte, metodologÃ­a reproducible

4. **PresentaciÃ³n Profesional:** Video, artÃ­culo y cÃ³digo de calidad superior

5. **Stack Moderno:** FastAPI + Nuxt 3 demuestra conocimiento de tecnologÃ­as actuales


### Contacto y Soporte

Para dudas durante la implementaciÃ³n:
- **Carlos Bocanegra:** Backend + Algoritmos
- **Arthur Zizumbo:** ML + Prithvi
- **Luis VÃ¡zquez:** Frontend + VisualizaciÃ³n
- **Edgar Oviedo:** DocumentaciÃ³n + CoordinaciÃ³n

---

## ğŸ“ ANEXOS

### A. Comandos Ãštiles

```bash
# Backend (FastAPI)
cd backend
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
pip install -r requirements.txt
uvicorn app.main:app --reload --port 8000

# Frontend (Nuxt 3)
cd frontend
npm install
npm run dev  # http://localhost:3000

# Descargar Prithvi
huggingface-cli download ibm-nasa-geospatial/Prithvi-EO-1.0-100M
```

### B. Recursos Adicionales

- **Prithvi Docs:** https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-1.0-100M
- **Sentinel Hub API:** https://docs.sentinel-hub.com/
- **FastAPI Tutorial:** https://fastapi.tiangolo.com/tutorial/
- **Nuxt 3 Docs:** https://nuxt.com/docs
- **MMSegmentation:** https://mmsegmentation.readthedocs.io/

### C. Datasets de Prueba

- **SEN12MS:** https://mediatum.ub.tum.de/1474000
- **BreizhCrops:** https://github.com/dl4sits/BreizhCrops
- **Fields of the World:** https://fieldsofthe.world/

---

**Documento creado:** Noviembre 2025  
**VersiÃ³n:** 2.0  
**Autores:** Equipo 24-Region Growing

**Â¡Ã‰xito en el proyecto! ğŸš€**
