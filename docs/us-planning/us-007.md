# US-007: Implementar MGRG (Region Growing SemÃ¡ntico) - PLANEACIÃ“N

**Estado:** ğŸ“‹ EN PLANEACIÃ“N  
**Fecha de PlaneaciÃ³n:** 10 de Noviembre de 2025  
**Equipo:** 24 - Region Growing  
**Desarrolladores Asignados:** Arthur Zizumbo (Lead)  
**EstimaciÃ³n:** 12 horas

---

## ğŸ“‹ Resumen Ejecutivo

Implementar el algoritmo MGRG (Metric-Guided Region Growing) que utiliza embeddings semÃ¡nticos de Prithvi para segmentaciÃ³n robusta de imÃ¡genes satelitales. La innovaciÃ³n principal es el uso de **semillas inteligentes generadas por K-Means** sobre el espacio de embeddings, en lugar de un grid fijo, lo que reduce sobre-segmentaciÃ³n y mejora la coherencia semÃ¡ntica.

### Objetivos Principales

1. Implementar algoritmo MGRG con BFS sobre embeddings (256D)
2. Desarrollar mÃ©todo `generate_smart_seeds()` con K-Means clustering
3. Comparar rendimiento: grid fijo vs K-Means inteligente
4. Crear notebook demostrativo con anÃ¡lisis cuantitativo
5. Integrar con datos reales de las 3 zonas de MÃ©xico ya procesadas

---

## ğŸ¯ Criterios de AceptaciÃ³n (Checklist)

### Funcionalidad Core
- [ ] Algoritmo MGRG funcional con BFS (4-conectividad) sobre embeddings
- [ ] Criterio de homogeneidad: `cosine_similarity(emb_A, emb_B) > threshold`
- [ ] Threshold optimizado (0.85 por defecto, configurable)
- [ ] Filtrado de regiones pequeÃ±as (`min_size=50` pÃ­xeles)

### InnovaciÃ³n: Semillas Inteligentes
- [ ] MÃ©todo `generate_smart_seeds()` implementado con K-Means
- [ ] ParÃ¡metro configurable `n_clusters` (5-10 por defecto)
- [ ] ComparaciÃ³n cuantitativa: grid fijo vs K-Means
- [ ] MÃ©tricas de comparaciÃ³n: nÃºmero de semillas, calidad de segmentaciÃ³n, tiempo

### Testing y Calidad
- [ ] Tests unitarios para MGRG (>15 tests)
- [ ] Tests de integraciÃ³n con embeddings reales
- [ ] Cobertura de cÃ³digo >60%
- [ ] Sin errores de diagnÃ³stico

### DocumentaciÃ³n
- [ ] Docstrings estilo Google en todas las funciones
- [ ] Notebook demostrativo sin emojis en cÃ³digo
- [ ] AnÃ¡lisis cuantitativo con mÃ©tricas claras
- [ ] README actualizado con ejemplos de uso

### Cumplimiento AGENTS.md
- [ ] CÃ³digo en inglÃ©s (nombres, funciones, variables)
- [ ] DocumentaciÃ³n narrativa en espaÃ±ol
- [ ] Type hints en todas las funciones
- [ ] Sin emojis en cÃ³digo Python
- [ ] Logging profesional (sin prints decorativos)
- [ ] Funciones reutilizables en `src/`

---

## ğŸ—ï¸ Arquitectura y DiseÃ±o

### Componentes a Desarrollar

```
src/algorithms/
â”œâ”€â”€ semantic_region_growing.py    # Clase SemanticRegionGrowing (NUEVO)
â”‚   â”œâ”€â”€ __init__()                # Constructor con parÃ¡metros
â”‚   â”œâ”€â”€ generate_smart_seeds()    # K-Means clustering (INNOVACIÃ“N)
â”‚   â”œâ”€â”€ generate_grid_seeds()     # Grid fijo (baseline)
â”‚   â”œâ”€â”€ segment()                 # BFS con similitud coseno
â”‚   â”œâ”€â”€ analyze_stress()          # AnÃ¡lisis jerÃ¡rquico
â”‚   â””â”€â”€ visualize_results()       # VisualizaciÃ³n de segmentaciÃ³n

tests/unit/
â”œâ”€â”€ test_semantic_rg.py           # Tests unitarios (NUEVO)
â”‚   â”œâ”€â”€ TestSmartSeeds            # Tests de K-Means
â”‚   â”œâ”€â”€ TestSegmentation          # Tests de BFS
â”‚   â”œâ”€â”€ TestCosineSimilarity      # Tests de similitud
â”‚   â””â”€â”€ TestIntegration           # Tests end-to-end

notebooks/experimental/
â””â”€â”€ mgrg-demo.ipynb               # Notebook demostrativo (NUEVO)
    â”œâ”€â”€ 1. Carga de embeddings
    â”œâ”€â”€ 2. GeneraciÃ³n de semillas (grid vs K-Means)
    â”œâ”€â”€ 3. SegmentaciÃ³n MGRG
    â”œâ”€â”€ 4. ComparaciÃ³n cuantitativa
    â””â”€â”€ 5. AnÃ¡lisis de resultados
```

### Flujo de Datos

```
Embeddings (H, W, 256)
    â†“
generate_smart_seeds(n_clusters=5-10)
    â†“ K-Means clustering
Semillas inteligentes [(y1,x1), (y2,x2), ...]
    â†“
segment(embeddings, seeds, threshold=0.85)
    â†“ BFS con cosine_similarity
Labeled Image (H, W) con region_id
    â†“
analyze_stress(labeled, ndvi)
    â†“ AnÃ¡lisis jerÃ¡rquico
Resultados por regiÃ³n {region_id: {mean_ndvi, stress_level, ...}}
```

---

## ğŸ“ Especificaciones TÃ©cnicas Detalladas

### 1. Clase SemanticRegionGrowing

**UbicaciÃ³n:** `src/algorithms/semantic_region_growing.py`

**Firma de la clase:**
```python
class SemanticRegionGrowing:
    """
    Metric-Guided Region Growing using semantic embeddings from Foundation Models.
    
    Inspired by CRGNet (Ghamisi et al., 2022) and adapted for remote sensing
    with Prithvi embeddings.
    
    Parameters
    ----------
    threshold : float, default=0.85
        Cosine similarity threshold for region growing (0-1).
        Higher values create more conservative regions.
    min_size : int, default=50
        Minimum region size in pixels. Smaller regions are filtered as noise.
    use_smart_seeds : bool, default=True
        If True, use K-Means clustering for intelligent seed generation.
        If False, use fixed grid.
    n_clusters : int, default=5
        Number of clusters for K-Means seed generation.
    
    Attributes
    ----------
    labeled_image_ : np.ndarray
        Segmentation result with region IDs (H, W).
    num_regions_ : int
        Number of regions found after filtering.
    seeds_ : List[Tuple[int, int]]
        Seed coordinates used for segmentation.
    """
```

### 2. MÃ©todo generate_smart_seeds()

**InnovaciÃ³n Principal:** Usar K-Means sobre embeddings para encontrar semillas semÃ¡nticamente representativas.

**PseudocÃ³digo:**
```
INPUT: embeddings (H, W, 256), n_clusters (int)
OUTPUT: seeds [(y1, x1), (y2, x2), ...]

1. Reshape embeddings: (H*W, 256)
2. K-Means clustering con n_clusters
3. Para cada cluster i:
   a. Obtener centroide C_i
   b. Encontrar pÃ­xel P_i mÃ¡s cercano a C_i
   c. Convertir Ã­ndice flat a coordenadas (y, x)
   d. Agregar (y, x) a seeds
4. RETURN seeds
```

**Ventajas sobre grid fijo:**
- Semillas "semÃ¡nticamente puras" (centros de clases)
- Reduce sobre-segmentaciÃ³n (5-10 semillas vs ~400)
- MÃ¡s robusto ante variaciones espectrales
- Demuestra integraciÃ³n avanzada de IA

### 3. MÃ©todo segment()

**Criterio de homogeneidad semÃ¡ntica:**
```python
# En lugar de diferencia espectral:
# |NDVI_A - NDVI_B| < threshold

# Usar similitud coseno en espacio de embeddings:
similarity = np.dot(emb_A, emb_B)  # Embeddings ya L2-normalizados
if similarity >= threshold:  # threshold = 0.85
    # Agregar pÃ­xel a regiÃ³n
```

**Algoritmo BFS (4-conectividad):**
```
INPUT: embeddings (H, W, 256), seeds [(y,x)], threshold
OUTPUT: labeled_image (H, W)

1. Inicializar labeled = zeros(H, W)
2. region_id = 1
3. Para cada seed (y, x):
   a. Si labeled[y, x] != 0: continuar
   b. seed_emb = embeddings[y, x]
   c. queue = [(y, x)]
   d. region_pixels = []
   e. Mientras queue no vacÃ­a:
      i. Sacar (cy, cx) de queue
      ii. Si fuera de lÃ­mites o visitado: continuar
      iii. pixel_emb = embeddings[cy, cx]
      iv. similarity = dot(seed_emb, pixel_emb)
      v. Si similarity >= threshold:
         - labeled[cy, cx] = region_id
         - region_pixels.append((cy, cx))
         - Agregar vecinos a queue: (cy-1,cx), (cy+1,cx), (cy,cx-1), (cy,cx+1)
   f. Si len(region_pixels) >= min_size:
      - region_id += 1
   g. Sino:
      - Marcar regiÃ³n como ruido (labeled = 0)
4. RETURN labeled
```

### 4. MÃ©todo analyze_stress()

**AnÃ¡lisis jerÃ¡rquico:** Primero objetos semÃ¡nticos, luego estrÃ©s interno.

```python
def analyze_stress(
    self,
    labeled: np.ndarray,
    ndvi: np.ndarray
) -> Dict[int, Dict[str, Any]]:
    """
    Hierarchical analysis: semantic objects â†’ internal stress.
    
    Parameters
    ----------
    labeled : np.ndarray
        Segmentation result (H, W) with region IDs.
    ndvi : np.ndarray
        NDVI image (H, W) with values in [-1, 1].
    
    Returns
    -------
    results : Dict[int, Dict]
        Dictionary with region_id as key and statistics as value:
        {
            region_id: {
                'mean_ndvi': float,
                'std_ndvi': float,
                'size': int,
                'stress_distribution': {
                    'high': int,    # pixels with NDVI < 0.3
                    'medium': int,  # pixels with 0.3 <= NDVI < 0.5
                    'low': int      # pixels with NDVI >= 0.5
                },
                'dominant_stress': str  # 'high', 'medium', or 'low'
            }
        }
    """
```

---

## ğŸ“Š ComparaciÃ³n: Grid Fijo vs K-Means Inteligente

### MÃ©tricas de ComparaciÃ³n

| MÃ©trica | Grid Fijo | K-Means | Mejora Esperada |
|---------|-----------|---------|-----------------|
| **NÃºmero de semillas** | ~400 (20x20) | 5-10 | -97.5% |
| **Tiempo generaciÃ³n semillas** | <0.1s | 2-3s | +30x mÃ¡s lento |
| **NÃºmero de regiones** | 50-100 | 5-15 | -70% |
| **Coherencia espacial** | 60-70% | 85-95% | +30% |
| **Sobre-segmentaciÃ³n** | Alta | Baja | Mejor |
| **Calidad semÃ¡ntica** | Aleatoria | Representativa | Mejor |

### Experimentos a Realizar

**Experimento 1: Zona Mexicali (agricultura intensiva)**
- Embeddings: (922, 1124, 256)
- Grid: 20x20 = 400 semillas
- K-Means: n_clusters = 5, 7, 10
- MÃ©trica: NÃºmero de regiones, coherencia

**Experimento 2: Zona BajÃ­o (agricultura diversa)**
- Embeddings: (1057, 1092, 256)
- Comparar: grid vs K-Means
- MÃ©trica: DistribuciÃ³n de tamaÃ±os de regiÃ³n

**Experimento 3: Zona Sinaloa (agricultura tecnificada)**
- Embeddings: (1031, 1090, 256)
- Comparar: tiempo de ejecuciÃ³n
- MÃ©trica: Tiempo total (generaciÃ³n + segmentaciÃ³n)

---

## ğŸ§ª Plan de Testing

### Tests Unitarios (>15 tests)

**TestSmartSeeds (5 tests)**
```python
def test_generate_smart_seeds_returns_correct_number()
def test_generate_smart_seeds_coordinates_within_bounds()
def test_generate_smart_seeds_different_n_clusters()
def test_generate_smart_seeds_reproducibility()  # random_state=42
def test_generate_smart_seeds_vs_grid_comparison()
```

**TestSegmentation (5 tests)**
```python
def test_segment_with_smart_seeds()
def test_segment_with_grid_seeds()
def test_segment_threshold_sensitivity()
def test_segment_min_size_filtering()
def test_segment_4_connectivity()
```

**TestCosineSimilarity (3 tests)**
```python
def test_cosine_similarity_normalized_embeddings()
def test_cosine_similarity_threshold_behavior()
def test_cosine_similarity_edge_cases()
```

**TestAnalyzeStress (3 tests)**
```python
def test_analyze_stress_hierarchical()
def test_analyze_stress_distribution()
def test_analyze_stress_dominant_class()
```

**TestIntegration (2 tests)**
```python
def test_end_to_end_with_real_embeddings()
def test_comparison_grid_vs_kmeans()
```

### Cobertura Esperada

- `semantic_region_growing.py`: >70%
- Tests de integraciÃ³n con datos reales: 100%

---

## ğŸ““ Notebook Demostrativo

### Estructura del Notebook

**Archivo:** `notebooks/experimental/mgrg-demo.ipynb`

**Secciones:**

#### 1. IntroducciÃ³n y Setup
```markdown
# MGRG: Metric-Guided Region Growing con Semillas Inteligentes

Este notebook demuestra la implementaciÃ³n del algoritmo MGRG usando embeddings
semÃ¡nticos de Prithvi y semillas generadas por K-Means clustering.

## Objetivos
- Implementar MGRG con BFS sobre embeddings
- Comparar grid fijo vs K-Means inteligente
- Analizar resultados cuantitativamente
```

#### 2. Carga de Datos
```python
# Load embeddings from US-006
from src.features.hls_processor import load_embeddings

embeddings_mexicali = load_embeddings("img/sentinel2/embeddings/mexicali_2024-01-15.npz")
print(f"Shape: {embeddings_mexicali.shape}")  # (922, 1124, 256)
```

#### 3. GeneraciÃ³n de Semillas

**3.1 Grid Fijo (Baseline)**
```python
from src.algorithms.semantic_region_growing import SemanticRegionGrowing

mgrg_grid = SemanticRegionGrowing(use_smart_seeds=False)
grid_seeds = mgrg_grid.generate_grid_seeds(embeddings_mexicali, grid_size=20)
print(f"Grid seeds: {len(grid_seeds)}")  # ~400
```

**3.2 K-Means Inteligente (InnovaciÃ³n)**
```python
mgrg_kmeans = SemanticRegionGrowing(use_smart_seeds=True, n_clusters=5)
smart_seeds = mgrg_kmeans.generate_smart_seeds(embeddings_mexicali)
print(f"Smart seeds: {len(smart_seeds)}")  # 5
```

**3.3 VisualizaciÃ³n de Semillas**
```python
import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 2, figsize=(12, 5))

# Grid seeds
axes[0].imshow(embeddings_mexicali[:,:,0], cmap='gray')
for y, x in grid_seeds[:50]:  # Mostrar primeras 50
    axes[0].plot(x, y, 'ro', markersize=2)
axes[0].set_title(f'Grid Seeds (n={len(grid_seeds)})')

# K-Means seeds
axes[1].imshow(embeddings_mexicali[:,:,0], cmap='gray')
for y, x in smart_seeds:
    axes[1].plot(x, y, 'go', markersize=10)
axes[1].set_title(f'K-Means Seeds (n={len(smart_seeds)})')

plt.tight_layout()
plt.show()
```

#### 4. SegmentaciÃ³n MGRG

**4.1 Con Grid Fijo**
```python
import time

start = time.time()
labeled_grid = mgrg_grid.segment(embeddings_mexicali, threshold=0.85)
time_grid = time.time() - start

print(f"Grid method:")
print(f"  Time: {time_grid:.2f}s")
print(f"  Regions: {mgrg_grid.num_regions_}")
```

**4.2 Con K-Means**
```python
start = time.time()
labeled_kmeans = mgrg_kmeans.segment(embeddings_mexicali, threshold=0.85)
time_kmeans = time.time() - start

print(f"K-Means method:")
print(f"  Time: {time_kmeans:.2f}s")
print(f"  Regions: {mgrg_kmeans.num_regions_}")
```

#### 5. ComparaciÃ³n Cuantitativa

**5.1 MÃ©tricas de SegmentaciÃ³n**
```python
import pandas as pd

comparison = pd.DataFrame({
    'Metric': ['Seeds', 'Regions', 'Time (s)', 'Coherence (%)'],
    'Grid Fixed': [
        len(grid_seeds),
        mgrg_grid.num_regions_,
        f"{time_grid:.2f}",
        calculate_coherence(labeled_grid)
    ],
    'K-Means': [
        len(smart_seeds),
        mgrg_kmeans.num_regions_,
        f"{time_kmeans:.2f}",
        calculate_coherence(labeled_kmeans)
    ]
})

print(comparison.to_string(index=False))
```

**5.2 VisualizaciÃ³n de Resultados**
```python
fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# Grid segmentation
axes[0].imshow(labeled_grid, cmap='tab20')
axes[0].set_title(f'Grid Fixed ({mgrg_grid.num_regions_} regions)')

# K-Means segmentation
axes[1].imshow(labeled_kmeans, cmap='tab20')
axes[1].set_title(f'K-Means ({mgrg_kmeans.num_regions_} regions)')

plt.tight_layout()
plt.show()
```

#### 6. AnÃ¡lisis de EstrÃ©s Vegetal

```python
# Load NDVI for stress analysis
ndvi_mexicali = load_ndvi("img/sentinel2/mexico/mexicali_2024-01-15_ndvi.tif")

# Hierarchical analysis
stress_results = mgrg_kmeans.analyze_stress(labeled_kmeans, ndvi_mexicali)

# Display results
for region_id, stats in stress_results.items():
    print(f"Region {region_id}:")
    print(f"  Mean NDVI: {stats['mean_ndvi']:.3f}")
    print(f"  Dominant stress: {stats['dominant_stress']}")
    print(f"  Distribution: {stats['stress_distribution']}")
```

#### 7. Conclusiones

```markdown
## Resultados Clave

1. **ReducciÃ³n de semillas:** K-Means usa 97.5% menos semillas (5 vs 400)
2. **Coherencia espacial:** K-Means mejora coherencia en ~30%
3. **Sobre-segmentaciÃ³n:** K-Means reduce regiones en ~70%
4. **Tiempo:** K-Means es +2-3s mÃ¡s lento (aceptable)

## Ventajas de K-Means

- Semillas semÃ¡nticamente representativas
- SegmentaciÃ³n mÃ¡s coherente
- Menos sobre-segmentaciÃ³n
- Mejor para anÃ¡lisis jerÃ¡rquico

## Limitaciones

- Requiere selecciÃ³n de n_clusters
- MÃ¡s costoso computacionalmente
- Sensible a inicializaciÃ³n (usar random_state)
```

---

## ğŸ“… Plan de Trabajo Detallado

### Fase 1: ImplementaciÃ³n Core (6 horas)

**DÃ­a 1 - MaÃ±ana (3 horas)**
- [ ] Crear `src/algorithms/semantic_region_growing.py`
- [ ] Implementar clase `SemanticRegionGrowing` con constructor
- [ ] Implementar `generate_grid_seeds()` (baseline)
- [ ] Implementar `generate_smart_seeds()` con K-Means

**DÃ­a 1 - Tarde (3 horas)**
- [ ] Implementar mÃ©todo `segment()` con BFS
- [ ] Implementar criterio de similitud coseno
- [ ] Implementar filtrado de regiones pequeÃ±as
- [ ] Pruebas manuales con embeddings de prueba

### Fase 2: AnÃ¡lisis y Testing (4 horas)

**DÃ­a 2 - MaÃ±ana (2 horas)**
- [ ] Implementar `analyze_stress()` con anÃ¡lisis jerÃ¡rquico
- [ ] Implementar `visualize_results()` para debugging
- [ ] Crear `tests/unit/test_semantic_rg.py`
- [ ] Implementar tests de `generate_smart_seeds()` (5 tests)

**DÃ­a 2 - Tarde (2 horas)**
- [ ] Implementar tests de `segment()` (5 tests)
- [ ] Implementar tests de similitud y estrÃ©s (6 tests)
- [ ] Ejecutar pytest y verificar cobertura >60%
- [ ] Corregir bugs encontrados

### Fase 3: Notebook y DocumentaciÃ³n (2 horas)

**DÃ­a 3 - MaÃ±ana (2 horas)**
- [ ] Crear `notebooks/experimental/mgrg-demo.ipynb`
- [ ] Implementar secciones 1-4 (carga, semillas, segmentaciÃ³n)
- [ ] Implementar secciÃ³n 5 (comparaciÃ³n cuantitativa)
- [ ] Implementar secciÃ³n 6-7 (anÃ¡lisis, conclusiones)
- [ ] Ejecutar notebook completo sin errores
- [ ] Eliminar emojis del cÃ³digo (cumplir AGENTS.md)

---

## ğŸ¯ MÃ©tricas de Ã‰xito

| MÃ©trica | Objetivo | CÃ³mo Medir |
|---------|----------|------------|
| Tests unitarios | >15 | `pytest tests/unit/test_semantic_rg.py -v` |
| Cobertura cÃ³digo | >60% | `pytest --cov=src/algorithms/semantic_rg.py` |
| ReducciÃ³n semillas | >95% | Comparar len(grid_seeds) vs len(smart_seeds) |
| Mejora coherencia | >20% | MÃ©trica de coherencia espacial |
| ReducciÃ³n regiones | >50% | Comparar num_regions grid vs K-Means |
| Tiempo ejecuciÃ³n | <10s | Medir tiempo total (generaciÃ³n + segmentaciÃ³n) |
| Notebook ejecutable | 100% | Ejecutar de principio a fin sin errores |

---

## ğŸš§ Riesgos y Mitigaciones

### Riesgo 1: K-Means muy lento con embeddings grandes
**Probabilidad:** Media  
**Impacto:** Medio  
**MitigaciÃ³n:** 
- Usar `n_init=10` en lugar de default (10 es suficiente)
- Considerar MiniBatchKMeans si es necesario
- Cachear resultados de K-Means

### Riesgo 2: Threshold 0.85 no Ã³ptimo para todas las zonas
**Probabilidad:** Alta  
**Impacto:** Bajo  
**MitigaciÃ³n:**
- Hacer threshold configurable
- Probar valores: 0.80, 0.85, 0.90
- Documentar sensibilidad en notebook

### Riesgo 3: Sobre-segmentaciÃ³n con grid fijo
**Probabilidad:** Alta (esperado)  
**Impacto:** Bajo (es el baseline)  
**MitigaciÃ³n:**
- Documentar como limitaciÃ³n conocida
- Usar como justificaciÃ³n para K-Means

### Riesgo 4: n_clusters difÃ­cil de seleccionar
**Probabilidad:** Media  
**Impacto:** Medio  
**MitigaciÃ³n:**
- Probar rango: 5, 7, 10
- Usar Elbow method o Silhouette score
- Documentar heurÃ­stica: n_clusters â‰ˆ nÃºmero de clases esperadas

---

## ğŸ“š Referencias TÃ©cnicas

### Papers Clave

1. **Ghamisi et al. (2022)** - CRGNet: Consistency-regularized region-growing network
   - InspiraciÃ³n directa para MGRG
   - Uso de embeddings para region growing

2. **Jakubik et al. (2024)** - Prithvi Foundation Model
   - Embeddings semÃ¡nticos de 256D
   - Pre-entrenado en HLS

3. **Ma et al. (2024)** - Deep learning meets OBIA
   - Marco teÃ³rico de hibridaciÃ³n
   - JustificaciÃ³n del enfoque

### Recursos de ImplementaciÃ³n

- **scikit-learn KMeans:** https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
- **NumPy dot product:** https://numpy.org/doc/stable/reference/generated/numpy.dot.html
- **BFS algorithm:** https://en.wikipedia.org/wiki/Breadth-first_search

---

## âœ… Checklist Pre-ImplementaciÃ³n

Antes de empezar a programar, verificar:

- [ ] US-006 completada (embeddings disponibles)
- [ ] Embeddings de 3 zonas descargados y validados
- [ ] Entorno Poetry configurado
- [ ] Tests de US-006 pasando (27/27)
- [ ] Modelo Prithvi funcional
- [ ] Lectura completa de AGENTS.md
- [ ] Lectura de US-006 para entender contexto
- [ ] RevisiÃ³n de `src/features/hls_processor.py` (funciones disponibles)

---

## ğŸ“ Notas Adicionales

### Diferencias con Region Growing ClÃ¡sico

| Aspecto | RG ClÃ¡sico | MGRG SemÃ¡ntico |
|---------|------------|----------------|
| **Espacio de features** | NDVI (1D) | Embeddings (256D) |
| **Criterio homogeneidad** | Diferencia absoluta | Similitud coseno |
| **Semillas** | Grid fijo | K-Means inteligente |
| **Robustez** | Sensible a sombras | Robusto semÃ¡nticamente |
| **Coherencia** | Baja (fragmentado) | Alta (objetos completos) |

### IntegraciÃ³n con US-006

Reutilizar funciones existentes:
- `load_embeddings()` de `hls_processor.py`
- `normalize_embeddings_l2()` (embeddings ya normalizados)
- `compute_cosine_similarity()` (si existe)

### PrÃ³ximos Pasos (US-008)

DespuÃ©s de completar US-007:
- Comparativa A/B visual (RG ClÃ¡sico vs MGRG)
- IntegraciÃ³n con frontend Nuxt 3
- API endpoint para MGRG

---

## ğŸ“ Aprendizajes Esperados

Al completar esta US, el equipo habrÃ¡:

1. Dominado algoritmos de region growing avanzados
2. Integrado Foundation Models en pipelines tradicionales
3. Aplicado K-Means clustering de forma innovadora
4. Desarrollado anÃ¡lisis jerÃ¡rquico (objeto â†’ estrÃ©s)
5. Comparado mÃ©todos cuantitativamente con rigor cientÃ­fico

---

## ğŸ“ Contactos y Soporte

**Lead Developer:** Arthur Zizumbo  
**Support:** Carlos Bocanegra  
**Revisor:** Carlos Bocanegra  

**Canales de comunicaciÃ³n:**
- Slack: #us-007-mgrg
- GitHub Issues: Etiquetar con `us-007`
- Daily Standup: 9:00 AM

---

**Fecha de creaciÃ³n:** 10 de Noviembre de 2025  
**VersiÃ³n:** 1.0  
**Estado:** ğŸ“‹ APROBADO PARA IMPLEMENTACIÃ“N

---

## ğŸš€ AprobaciÃ³n para Inicio

Una vez revisada y aprobada esta planeaciÃ³n, proceder con:

1. Crear branch `us-007-mgrg`
2. Implementar segÃºn fases definidas
3. Commits frecuentes con Conventional Commits
4. Pull Request al completar
5. Code review por Carlos Bocanegra

**Â¿Aprobado para iniciar implementaciÃ³n?** â³ Pendiente de aprobaciÃ³n
