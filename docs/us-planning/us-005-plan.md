# US-005: Descargar y Configurar Prithvi - Plan de Implementaci√≥n üìã

**Epic:** Innovaci√≥n SOTA (D√≠as 4-7)  
**Prioridad:** Alta (Bloqueante para US-006, US-007)  
**Estimaci√≥n:** 4 horas  
**Responsable:** Arthur Zizumbo  
**Estado:** üìù **PLANEACI√ìN**  
**Fecha de Planeaci√≥n:** 8 de Noviembre de 2025

---

## üìã Historia de Usuario

**Como** investigador  
**Quiero** descargar y configurar el modelo Prithvi-EO-1.0-100M  
**Para que** podamos extraer embeddings sem√°nticos de im√°genes Sentinel-2 y usarlos en el m√©todo MGRG

---

## üéØ Objetivos de la US

### Objetivo Principal
Configurar el modelo Foundation Prithvi-EO-1.0-100M de NASA/IBM para inferencia local en RTX 4070, verificando que funciona correctamente con im√°genes Sentinel-2 en formato HLS.

### Objetivos Espec√≠ficos
1. Descargar modelo pre-entrenado desde HuggingFace
2. Instalar dependencias necesarias (PyTorch, MMSegmentation, timm)
3. Crear m√≥dulo de carga del modelo en `src/models/`
4. Implementar test de inferencia con imagen de ejemplo
5. Verificar uso de memoria GPU (debe caber en 8GB VRAM)
6. Documentar configuraci√≥n y uso del modelo

---

## ‚úÖ Criterios de Aceptaci√≥n Detallados

### 1. Modelo Descargado ‚úÖ
- [ ] Modelo Prithvi-EO-1.0-100M descargado de HuggingFace
- [ ] Pesos del modelo guardados en `models/prithvi/`
- [ ] Archivo de configuraci√≥n del modelo disponible
- [ ] Verificaci√≥n de integridad (checksums)

### 2. Dependencias Instaladas ‚úÖ
- [ ] PyTorch 2.1+ con CUDA 12.9 (ya instalado en US-003)
- [ ] MMSegmentation 1.2+ instalado correctamente
- [ ] timm (PyTorch Image Models) instalado
- [ ] Todas las dependencias en `pyproject.toml`
- [ ] Sin conflictos de versiones

### 3. M√≥dulo de Carga Implementado ‚úÖ
- [ ] `src/models/prithvi_loader.py` creado
- [ ] Funci√≥n `load_prithvi_model()` implementada
- [ ] Funci√≥n `get_prithvi_encoder()` para extraer solo encoder
- [ ] Manejo de errores robusto
- [ ] Logging de carga del modelo
- [ ] Docstrings estilo Google en ingl√©s

### 4. Test de Inferencia Exitoso ‚úÖ
- [ ] Script `scripts/test_prithvi_inference.py` creado
- [ ] Test con imagen sint√©tica (6 bandas HLS)
- [ ] Test con imagen real Sentinel-2 (si disponible)
- [ ] Verificaci√≥n de shape de embeddings (H, W, 256)
- [ ] Tiempo de inferencia medido
- [ ] Sin errores de CUDA/GPU

### 5. Verificaci√≥n de VRAM ‚úÖ
- [ ] Uso de memoria GPU medido
- [ ] Confirmaci√≥n de que cabe en 8GB VRAM
- [ ] Optimizaciones aplicadas si es necesario (mixed precision)
- [ ] Documentaci√≥n de requisitos de memoria

### 6. Tests Unitarios ‚úÖ
- [ ] `tests/unit/test_prithvi_loader.py` creado
- [ ] Test de carga del modelo
- [ ] Test de inferencia b√°sica
- [ ] Test de manejo de errores
- [ ] M√≠nimo 5 tests implementados

### 7. Documentaci√≥n Completa ‚úÖ
- [ ] `src/models/README.md` con gu√≠a de uso
- [ ] Docstrings en todas las funciones
- [ ] Ejemplo de uso en notebook
- [ ] Troubleshooting de problemas comunes
- [ ] Referencias a paper original de Prithvi

---

## üì¶ Archivos a Crear

### Estructura de Archivos
```
src/models/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ prithvi_loader.py

scripts/
‚îî‚îÄ‚îÄ test_prithvi_inference.py

tests/unit/
‚îî‚îÄ‚îÄ test_prithvi_loader.py

models/
‚îî‚îÄ‚îÄ prithvi/
    ‚îú‚îÄ‚îÄ Prithvi_EO_V1_100M.pt
    ‚îî‚îÄ‚îÄ config.yaml

notebooks/exploratory/
‚îî‚îÄ‚îÄ 02_prithvi_inference_example.ipynb
```


---

## üîß Implementaci√≥n T√©cnica Detallada

### Fase 1: Instalaci√≥n de Dependencias (30 min)

#### 1.1 Actualizar pyproject.toml

```toml
[tool.poetry.dependencies]
# Ya instalado en US-003
torch = {version = "^2.8.0", source = "pytorch_cu129"}
torchvision = {version = "^0.19.0", source = "pytorch_cu129"}

# Nuevas dependencias para Prithvi
mmsegmentation = "^1.2.2"
mmcv = "^2.1.0"
timm = "^0.9.16"
einops = "^0.7.0"
```

#### 1.2 Instalar Dependencias

```bash
# Agregar dependencias
poetry add mmsegmentation mmcv timm einops

# Verificar instalaci√≥n
poetry run python -c "import mmseg; print(mmseg.__version__)"
poetry run python -c "import timm; print(timm.__version__)"
```

**Verificaci√≥n Esperada:**
- MMSegmentation: 1.2.2+
- MMCV: 2.1.0+
- timm: 0.9.16+

---

### Fase 2: Descarga del Modelo (45 min)

#### 2.1 Descargar desde HuggingFace

```python
# scripts/download_prithvi.py
"""
Script to download Prithvi-EO-1.0-100M model from HuggingFace.

Usage:
    poetry run python scripts/download_prithvi.py
"""
import os
from pathlib import Path
from huggingface_hub import hf_hub_download
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def download_prithvi_model(
    repo_id: str = "ibm-nasa-geospatial/Prithvi-EO-1.0-100M",
    model_dir: str = "models/prithvi"
) -> Path:
    """
    Download Prithvi model from HuggingFace Hub.
    
    Args:
        repo_id: HuggingFace repository ID
        model_dir: Local directory to save model
        
    Returns:
        Path to downloaded model file
    """
    model_path = Path(model_dir)
    model_path.mkdir(parents=True, exist_ok=True)
    
    logger.info(f"Downloading Prithvi model from {repo_id}...")
    
    # Download model weights
    model_file = hf_hub_download(
        repo_id=repo_id,
        filename="Prithvi_EO_V1_100M.pt",
        cache_dir=str(model_path),
        local_dir=str(model_path),
        local_dir_use_symlinks=False
    )
    
    logger.info(f"Model downloaded to: {model_file}")
    
    # Download config if available
    try:
        config_file = hf_hub_download(
            repo_id=repo_id,
            filename="config.yaml",
            cache_dir=str(model_path),
            local_dir=str(model_path),
            local_dir_use_symlinks=False
        )
        logger.info(f"Config downloaded to: {config_file}")
    except Exception as e:
        logger.warning(f"Config file not found: {e}")
    
    return Path(model_file)

if __name__ == "__main__":
    model_path = download_prithvi_model()
    print(f"\n‚úÖ Prithvi model ready at: {model_path}")
```

**Ejecuci√≥n:**
```bash
poetry run python scripts/download_prithvi.py
```

**Tama√±o Esperado:** ~400 MB

---

### Fase 3: Implementaci√≥n del Loader (60 min)

#### 3.1 M√≥dulo de Carga del Modelo

```python
# src/models/prithvi_loader.py
"""
Prithvi Foundation Model Loader.

This module provides utilities to load and use the Prithvi-EO-1.0-100M
foundation model for extracting semantic embeddings from Sentinel-2 imagery.

References:
    Jakubik et al. (2024). Foundation models for generalist geospatial AI.
    https://arxiv.org/abs/2310.18660
"""
import torch
import torch.nn as nn
from pathlib import Path
from typing import Optional, Tuple
import logging

logger = logging.getLogger(__name__)

class PrithviEncoder(nn.Module):
    """
    Prithvi encoder wrapper for extracting semantic embeddings.
    
    The encoder takes 6-band HLS imagery as input and outputs 256-dimensional
    embeddings at each spatial location.
    
    Input shape: (B, 6, H, W) - 6 bands: B02, B03, B04, B8A, B11, B12
    Output shape: (B, 256, H', W') - 256D embeddings
    
    Note:
        H' and W' may differ from H and W due to model architecture.
        Use interpolation to match original resolution if needed.
    """
    
    def __init__(self, model: nn.Module):
        super().__init__()
        self.model = model
        self.model.eval()  # Always in eval mode for inference
    
    @torch.no_grad()
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Extract semantic embeddings from HLS imagery.
        
        Args:
            x: Input tensor of shape (B, 6, H, W)
            
        Returns:
            Embeddings of shape (B, 256, H', W')
        """
        # Forward pass through encoder only
        features = self.model.forward_encoder(x)
        return features

def load_prithvi_model(
    model_path: Optional[str] = None,
    device: Optional[str] = None
) -> PrithviEncoder:
    """
    Load Prithvi-EO-1.0-100M model for inference.
    
    Args:
        model_path: Path to model weights. If None, uses default location.
        device: Device to load model on ('cuda' or 'cpu'). If None, auto-detects.
        
    Returns:
        PrithviEncoder instance ready for inference
        
    Raises:
        FileNotFoundError: If model file not found
        RuntimeError: If model loading fails
        
    Example:
        >>> encoder = load_prithvi_model()
        >>> embeddings = encoder(hls_image)
    """
    # Determine device
    if device is None:
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    logger.info(f"Loading Prithvi model on device: {device}")
    
    # Default model path
    if model_path is None:
        model_path = Path("models/prithvi/Prithvi_EO_V1_100M.pt")
    else:
        model_path = Path(model_path)
    
    # Check if model exists
    if not model_path.exists():
        raise FileNotFoundError(
            f"Prithvi model not found at {model_path}. "
            f"Run 'poetry run python scripts/download_prithvi.py' first."
        )
    
    try:
        # Load model checkpoint
        checkpoint = torch.load(model_path, map_location=device)
        
        # Extract model from checkpoint
        if 'model' in checkpoint:
            model_state = checkpoint['model']
        elif 'state_dict' in checkpoint:
            model_state = checkpoint['state_dict']
        else:
            model_state = checkpoint
        
        # Initialize model architecture
        # Note: This is a simplified version. Actual implementation
        # depends on Prithvi's architecture definition.
        from mmseg.models import build_segmentor
        
        # Build model (config should be loaded from file)
        model = build_segmentor(get_prithvi_config())
        model.load_state_dict(model_state, strict=False)
        model = model.to(device)
        
        # Wrap in encoder
        encoder = PrithviEncoder(model)
        
        logger.info("‚úÖ Prithvi model loaded successfully")
        return encoder
        
    except Exception as e:
        logger.error(f"Failed to load Prithvi model: {e}")
        raise RuntimeError(f"Model loading failed: {e}")

def get_prithvi_config() -> dict:
    """
    Get Prithvi model configuration.
    
    Returns:
        Model configuration dictionary
    """
    # Simplified config - actual config should be loaded from file
    config = {
        'type': 'EncoderDecoder',
        'backbone': {
            'type': 'VisionTransformer',
            'img_size': 224,
            'patch_size': 16,
            'in_channels': 6,  # HLS bands
            'embed_dims': 768,
            'num_layers': 12,
            'num_heads': 12,
            'mlp_ratio': 4,
            'out_indices': [11],  # Last layer
        },
        'decode_head': {
            'type': 'FCNHead',
            'in_channels': 768,
            'channels': 256,
            'num_classes': 256,  # Embedding dimension
        }
    }
    return config

def get_model_info(encoder: PrithviEncoder) -> dict:
    """
    Get information about loaded Prithvi model.
    
    Args:
        encoder: Loaded PrithviEncoder instance
        
    Returns:
        Dictionary with model information
    """
    total_params = sum(p.numel() for p in encoder.parameters())
    trainable_params = sum(p.numel() for p in encoder.parameters() if p.requires_grad)
    
    return {
        'total_parameters': total_params,
        'trainable_parameters': trainable_params,
        'device': next(encoder.parameters()).device,
        'dtype': next(encoder.parameters()).dtype,
    }
```


---

### Fase 4: Script de Test de Inferencia (45 min)

#### 4.1 Test con Imagen Sint√©tica

```python
# scripts/test_prithvi_inference.py
"""
Test Prithvi model inference with synthetic and real imagery.

This script verifies that:
1. Model loads correctly
2. Inference runs without errors
3. Output shape is correct
4. GPU memory usage is acceptable
5. Inference time is reasonable

Usage:
    poetry run python scripts/test_prithvi_inference.py
"""
import torch
import numpy as np
import time
from pathlib import Path
import logging

from src.models.prithvi_loader import load_prithvi_model, get_model_info

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def create_synthetic_hls_image(
    height: int = 224,
    width: int = 224,
    batch_size: int = 1
) -> torch.Tensor:
    """
    Create synthetic HLS image for testing.
    
    Args:
        height: Image height
        width: Image width
        batch_size: Batch size
        
    Returns:
        Synthetic HLS image tensor (B, 6, H, W)
    """
    # Generate random reflectance values (0-1 range)
    image = torch.rand(batch_size, 6, height, width)
    
    # Normalize to typical Sentinel-2 range
    image = (image - 0.5) / 0.2  # Mean=0, Std=1 approximately
    
    return image

def test_model_loading():
    """Test 1: Model loading"""
    logger.info("\n" + "="*70)
    logger.info("TEST 1: Model Loading")
    logger.info("="*70)
    
    try:
        encoder = load_prithvi_model()
        info = get_model_info(encoder)
        
        logger.info(f"‚úÖ Model loaded successfully")
        logger.info(f"   Total parameters: {info['total_parameters']:,}")
        logger.info(f"   Device: {info['device']}")
        logger.info(f"   Dtype: {info['dtype']}")
        
        return encoder
    except Exception as e:
        logger.error(f"‚ùå Model loading failed: {e}")
        raise

def test_inference_synthetic(encoder):
    """Test 2: Inference with synthetic image"""
    logger.info("\n" + "="*70)
    logger.info("TEST 2: Inference with Synthetic Image")
    logger.info("="*70)
    
    try:
        # Create synthetic image
        image = create_synthetic_hls_image(224, 224, 1)
        device = next(encoder.parameters()).device
        image = image.to(device)
        
        logger.info(f"Input shape: {image.shape}")
        
        # Measure inference time
        start_time = time.time()
        embeddings = encoder(image)
        inference_time = time.time() - start_time
        
        logger.info(f"‚úÖ Inference successful")
        logger.info(f"   Output shape: {embeddings.shape}")
        logger.info(f"   Inference time: {inference_time:.3f}s")
        logger.info(f"   Output range: [{embeddings.min():.3f}, {embeddings.max():.3f}]")
        
        # Verify output shape
        assert embeddings.shape[0] == 1, "Batch size mismatch"
        assert embeddings.shape[1] == 256, "Embedding dimension should be 256"
        
        return embeddings
    except Exception as e:
        logger.error(f"‚ùå Inference failed: {e}")
        raise

def test_gpu_memory(encoder):
    """Test 3: GPU memory usage"""
    logger.info("\n" + "="*70)
    logger.info("TEST 3: GPU Memory Usage")
    logger.info("="*70)
    
    if not torch.cuda.is_available():
        logger.warning("‚ö†Ô∏è  CUDA not available, skipping GPU memory test")
        return
    
    try:
        # Reset GPU memory stats
        torch.cuda.reset_peak_memory_stats()
        torch.cuda.empty_cache()
        
        # Run inference
        image = create_synthetic_hls_image(512, 512, 1)
        image = image.cuda()
        
        _ = encoder(image)
        
        # Get memory stats
        memory_allocated = torch.cuda.memory_allocated() / 1024**3  # GB
        memory_reserved = torch.cuda.memory_reserved() / 1024**3  # GB
        max_memory = torch.cuda.max_memory_allocated() / 1024**3  # GB
        
        logger.info(f"‚úÖ GPU memory test completed")
        logger.info(f"   Memory allocated: {memory_allocated:.2f} GB")
        logger.info(f"   Memory reserved: {memory_reserved:.2f} GB")
        logger.info(f"   Peak memory: {max_memory:.2f} GB")
        
        # Verify it fits in 8GB VRAM
        if max_memory > 7.5:
            logger.warning(f"‚ö†Ô∏è  Peak memory ({max_memory:.2f} GB) is close to 8GB limit")
        else:
            logger.info(f"   ‚úÖ Fits comfortably in 8GB VRAM")
        
    except Exception as e:
        logger.error(f"‚ùå GPU memory test failed: {e}")
        raise

def test_batch_inference(encoder):
    """Test 4: Batch inference"""
    logger.info("\n" + "="*70)
    logger.info("TEST 4: Batch Inference")
    logger.info("="*70)
    
    try:
        batch_sizes = [1, 2, 4]
        device = next(encoder.parameters()).device
        
        for batch_size in batch_sizes:
            image = create_synthetic_hls_image(224, 224, batch_size)
            image = image.to(device)
            
            start_time = time.time()
            embeddings = encoder(image)
            inference_time = time.time() - start_time
            
            logger.info(f"Batch size {batch_size}:")
            logger.info(f"   Output shape: {embeddings.shape}")
            logger.info(f"   Time: {inference_time:.3f}s ({inference_time/batch_size:.3f}s per image)")
        
        logger.info("‚úÖ Batch inference test passed")
        
    except Exception as e:
        logger.error(f"‚ùå Batch inference test failed: {e}")
        raise

def test_different_resolutions(encoder):
    """Test 5: Different image resolutions"""
    logger.info("\n" + "="*70)
    logger.info("TEST 5: Different Image Resolutions")
    logger.info("="*70)
    
    try:
        resolutions = [(224, 224), (256, 256), (512, 512)]
        device = next(encoder.parameters()).device
        
        for height, width in resolutions:
            image = create_synthetic_hls_image(height, width, 1)
            image = image.to(device)
            
            start_time = time.time()
            embeddings = encoder(image)
            inference_time = time.time() - start_time
            
            logger.info(f"Resolution {height}x{width}:")
            logger.info(f"   Output shape: {embeddings.shape}")
            logger.info(f"   Time: {inference_time:.3f}s")
        
        logger.info("‚úÖ Resolution test passed")
        
    except Exception as e:
        logger.error(f"‚ùå Resolution test failed: {e}")
        raise

def main():
    """Run all tests"""
    logger.info("\n" + "#"*70)
    logger.info("# Prithvi Model Inference Tests")
    logger.info("#"*70)
    
    try:
        # Test 1: Load model
        encoder = test_model_loading()
        
        # Test 2: Synthetic inference
        test_inference_synthetic(encoder)
        
        # Test 3: GPU memory
        test_gpu_memory(encoder)
        
        # Test 4: Batch inference
        test_batch_inference(encoder)
        
        # Test 5: Different resolutions
        test_different_resolutions(encoder)
        
        logger.info("\n" + "="*70)
        logger.info("‚úÖ ALL TESTS PASSED")
        logger.info("="*70)
        logger.info("\nPrithvi model is ready for use in the project!")
        
    except Exception as e:
        logger.error("\n" + "="*70)
        logger.error("‚ùå TESTS FAILED")
        logger.error("="*70)
        logger.error(f"Error: {e}")
        raise

if __name__ == "__main__":
    main()
```

**Ejecuci√≥n:**
```bash
poetry run python scripts/test_prithvi_inference.py
```

**Salida Esperada:**
```
######################################################################
# Prithvi Model Inference Tests
######################################################################

======================================================================
TEST 1: Model Loading
======================================================================
Loading Prithvi model on device: cuda
‚úÖ Prithvi model loaded successfully
‚úÖ Model loaded successfully
   Total parameters: 100,234,567
   Device: cuda:0
   Dtype: torch.float32

======================================================================
TEST 2: Inference with Synthetic Image
======================================================================
Input shape: torch.Size([1, 6, 224, 224])
‚úÖ Inference successful
   Output shape: torch.Size([1, 256, 14, 14])
   Inference time: 0.123s
   Output range: [-2.345, 3.456]

======================================================================
TEST 3: GPU Memory Usage
======================================================================
‚úÖ GPU memory test completed
   Memory allocated: 1.23 GB
   Memory reserved: 1.45 GB
   Peak memory: 1.67 GB
   ‚úÖ Fits comfortably in 8GB VRAM

======================================================================
TEST 4: Batch Inference
======================================================================
Batch size 1:
   Output shape: torch.Size([1, 256, 14, 14])
   Time: 0.123s (0.123s per image)
Batch size 2:
   Output shape: torch.Size([2, 256, 14, 14])
   Time: 0.234s (0.117s per image)
Batch size 4:
   Output shape: torch.Size([4, 256, 14, 14])
   Time: 0.456s (0.114s per image)
‚úÖ Batch inference test passed

======================================================================
TEST 5: Different Image Resolutions
======================================================================
Resolution 224x224:
   Output shape: torch.Size([1, 256, 14, 14])
   Time: 0.123s
Resolution 256x256:
   Output shape: torch.Size([1, 256, 16, 16])
   Time: 0.145s
Resolution 512x512:
   Output shape: torch.Size([1, 256, 32, 32])
   Time: 0.456s
‚úÖ Resolution test passed

======================================================================
‚úÖ ALL TESTS PASSED
======================================================================

Prithvi model is ready for use in the project!
```


---

### Fase 5: Tests Unitarios (30 min)

#### 5.1 Tests del Loader

```python
# tests/unit/test_prithvi_loader.py
"""
Unit tests for Prithvi model loader.
"""
import pytest
import torch
from pathlib import Path
from unittest.mock import Mock, patch

from src.models.prithvi_loader import (
    load_prithvi_model,
    PrithviEncoder,
    get_model_info,
    get_prithvi_config
)

class TestPrithviLoader:
    """Tests for Prithvi model loading functionality."""
    
    def test_get_prithvi_config(self):
        """Test configuration retrieval."""
        config = get_prithvi_config()
        
        assert isinstance(config, dict)
        assert 'backbone' in config
        assert config['backbone']['in_channels'] == 6
        assert config['decode_head']['num_classes'] == 256
    
    @patch('src.models.prithvi_loader.Path.exists')
    def test_load_model_file_not_found(self, mock_exists):
        """Test error handling when model file not found."""
        mock_exists.return_value = False
        
        with pytest.raises(FileNotFoundError) as exc_info:
            load_prithvi_model()
        
        assert "not found" in str(exc_info.value).lower()
    
    def test_prithvi_encoder_initialization(self):
        """Test PrithviEncoder initialization."""
        mock_model = Mock()
        encoder = PrithviEncoder(mock_model)
        
        assert encoder.model == mock_model
        mock_model.eval.assert_called_once()
    
    def test_prithvi_encoder_forward_shape(self):
        """Test encoder forward pass output shape."""
        # Create mock model
        mock_model = Mock()
        mock_model.forward_encoder.return_value = torch.randn(1, 256, 14, 14)
        
        encoder = PrithviEncoder(mock_model)
        
        # Test forward pass
        input_tensor = torch.randn(1, 6, 224, 224)
        output = encoder(input_tensor)
        
        assert output.shape == (1, 256, 14, 14)
        mock_model.forward_encoder.assert_called_once()
    
    def test_get_model_info(self):
        """Test model information extraction."""
        # Create simple mock model
        mock_model = Mock()
        mock_param = torch.nn.Parameter(torch.randn(100, 100))
        mock_model.parameters.return_value = [mock_param]
        
        encoder = PrithviEncoder(mock_model)
        info = get_model_info(encoder)
        
        assert 'total_parameters' in info
        assert 'trainable_parameters' in info
        assert 'device' in info
        assert 'dtype' in info
        assert info['total_parameters'] == 10000  # 100 * 100

class TestPrithviInference:
    """Tests for Prithvi inference functionality."""
    
    @pytest.mark.skipif(not torch.cuda.is_available(), reason="CUDA not available")
    def test_inference_on_gpu(self):
        """Test inference runs on GPU if available."""
        # This test requires actual model - skip in CI
        pytest.skip("Requires downloaded Prithvi model")
    
    def test_inference_with_different_batch_sizes(self):
        """Test inference with various batch sizes."""
        mock_model = Mock()
        encoder = PrithviEncoder(mock_model)
        
        for batch_size in [1, 2, 4, 8]:
            mock_model.forward_encoder.return_value = torch.randn(batch_size, 256, 14, 14)
            input_tensor = torch.randn(batch_size, 6, 224, 224)
            output = encoder(input_tensor)
            
            assert output.shape[0] == batch_size
            assert output.shape[1] == 256
```

**Ejecuci√≥n:**
```bash
poetry run pytest tests/unit/test_prithvi_loader.py -v
```

---

### Fase 6: Documentaci√≥n (30 min)

#### 6.1 README del M√≥dulo

```markdown
# src/models/README.md

# Prithvi Foundation Model

This module provides utilities for loading and using the Prithvi-EO-1.0-100M foundation model for extracting semantic embeddings from Sentinel-2 imagery.

## Overview

Prithvi is a 100M parameter Vision Transformer pre-trained on Harmonized Landsat Sentinel-2 (HLS) imagery by NASA and IBM. It can extract rich semantic features from multispectral satellite imagery without task-specific fine-tuning.

## Model Details

- **Name:** Prithvi-EO-1.0-100M
- **Architecture:** Vision Transformer (ViT)
- **Parameters:** ~100 million
- **Input:** 6-band HLS imagery (B02, B03, B04, B8A, B11, B12)
- **Output:** 256-dimensional embeddings per spatial location
- **Pre-training:** Masked autoencoding on HLS imagery

## Installation

### 1. Download Model

```bash
poetry run python scripts/download_prithvi.py
```

This downloads the model to `models/prithvi/Prithvi_EO_V1_100M.pt` (~400 MB).

### 2. Install Dependencies

Dependencies are already in `pyproject.toml`:
- PyTorch 2.1+ with CUDA
- MMSegmentation 1.2+
- timm 0.9+

## Usage

### Basic Usage

```python
from src.models.prithvi_loader import load_prithvi_model
import torch

# Load model
encoder = load_prithvi_model()

# Prepare HLS image (6 bands: B02, B03, B04, B8A, B11, B12)
hls_image = torch.randn(1, 6, 224, 224)  # (B, C, H, W)

# Extract embeddings
embeddings = encoder(hls_image)  # (B, 256, H', W')

print(f"Input shape: {hls_image.shape}")
print(f"Output shape: {embeddings.shape}")
```

### With Real Sentinel-2 Data

```python
from src.utils.sentinel_download import download_sentinel2_bands
from src.models.prithvi_loader import load_prithvi_model
import torch
import numpy as np

# Download Sentinel-2 data
bbox = {'min_lon': -100.0, 'min_lat': 40.0, 'max_lon': -99.9, 'max_lat': 40.1}
data = download_sentinel2_bands(bbox, config)

# Stack HLS bands in correct order
hls_bands = np.stack([
    data['bands']['B02'],  # Blue
    data['bands']['B03'],  # Green
    data['bands']['B04'],  # Red
    data['bands']['B8A'],  # NIR Narrow (20m, needs resampling)
    data['bands']['B11'],  # SWIR1 (20m, needs resampling)
    data['bands']['B12'],  # SWIR2 (20m, needs resampling)
], axis=0)

# Convert to tensor and add batch dimension
hls_tensor = torch.from_numpy(hls_bands).unsqueeze(0).float()

# Normalize (important!)
hls_tensor = (hls_tensor - hls_tensor.mean()) / (hls_tensor.std() + 1e-8)

# Load model and extract embeddings
encoder = load_prithvi_model()
embeddings = encoder(hls_tensor)

# Interpolate to original resolution if needed
if embeddings.shape[2:] != hls_tensor.shape[2:]:
    embeddings = torch.nn.functional.interpolate(
        embeddings,
        size=hls_tensor.shape[2:],
        mode='bilinear',
        align_corners=False
    )

# Convert to numpy for further processing
embeddings_np = embeddings.squeeze(0).permute(1, 2, 0).cpu().numpy()
print(f"Embeddings shape: {embeddings_np.shape}")  # (H, W, 256)
```

## Important Notes

### HLS Band Order

Prithvi expects bands in this exact order:
1. B02 - Blue (490 nm) - 10m
2. B03 - Green (560 nm) - 10m
3. B04 - Red (665 nm) - 10m
4. B8A - NIR Narrow (865 nm) - 20m ‚ö†Ô∏è (NOT B08!)
5. B11 - SWIR1 (1610 nm) - 20m
6. B12 - SWIR2 (2190 nm) - 20m

**Critical:** Use B8A (20m), not B08 (10m). They are different bands!

### Resampling 20m Bands

Bands B8A, B11, B12 are at 20m resolution and must be resampled to 10m:

```python
from scipy.ndimage import zoom

# Resample 20m band to 10m
b8a_10m = zoom(b8a_20m, 2, order=1)  # Bilinear interpolation
```

### Normalization

Always normalize input images:

```python
# Per-image normalization (recommended)
image = (image - image.mean()) / (image.std() + 1e-8)

# Or use dataset statistics if available
mean = [0.485, 0.456, 0.406, 0.5, 0.5, 0.5]  # Example
std = [0.229, 0.224, 0.225, 0.2, 0.2, 0.2]
```

### GPU Memory

- Model uses ~400 MB for weights
- Inference on 512x512 image: ~1.5 GB total
- Fits comfortably in 8GB VRAM (RTX 4070)

## Testing

Run inference tests:

```bash
poetry run python scripts/test_prithvi_inference.py
```

Run unit tests:

```bash
poetry run pytest tests/unit/test_prithvi_loader.py -v
```

## Troubleshooting

### Model Not Found

```
FileNotFoundError: Prithvi model not found
```

**Solution:** Download the model first:
```bash
poetry run python scripts/download_prithvi.py
```

### CUDA Out of Memory

```
RuntimeError: CUDA out of memory
```

**Solutions:**
1. Reduce batch size
2. Reduce image resolution
3. Use mixed precision (FP16)
4. Clear GPU cache: `torch.cuda.empty_cache()`

### Wrong Band Order

```
RuntimeError: Expected 6 channels, got X
```

**Solution:** Ensure bands are stacked in correct HLS order (see above).

## References

- **Paper:** Jakubik et al. (2024). Foundation models for generalist geospatial AI. arXiv:2310.18660
- **HuggingFace:** https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-1.0-100M
- **HLS Specification:** Claverie et al. (2018). The Harmonized Landsat and Sentinel-2 surface reflectance data set.

## License

Prithvi model is released under Apache 2.0 license by IBM and NASA.
```


---

## üìä Plan de Ejecuci√≥n por Fases

### Resumen de Tiempos

| Fase | Actividad | Tiempo Estimado | Responsable |
|------|-----------|-----------------|-------------|
| 1 | Instalaci√≥n de dependencias | 30 min | Arthur |
| 2 | Descarga del modelo | 45 min | Arthur |
| 3 | Implementaci√≥n del loader | 60 min | Arthur |
| 4 | Script de test de inferencia | 45 min | Arthur |
| 5 | Tests unitarios | 30 min | Arthur |
| 6 | Documentaci√≥n | 30 min | Arthur |
| **Total** | | **4 horas** | |

### Orden de Ejecuci√≥n

```
D√≠a 4 (Inicio de √âpica 2)
‚îú‚îÄ‚îÄ [09:00-09:30] Fase 1: Instalar dependencias
‚îÇ   ‚îú‚îÄ‚îÄ Actualizar pyproject.toml
‚îÇ   ‚îú‚îÄ‚îÄ poetry add mmsegmentation mmcv timm einops
‚îÇ   ‚îî‚îÄ‚îÄ Verificar instalaci√≥n
‚îÇ
‚îú‚îÄ‚îÄ [09:30-10:15] Fase 2: Descargar modelo
‚îÇ   ‚îú‚îÄ‚îÄ Crear scripts/download_prithvi.py
‚îÇ   ‚îú‚îÄ‚îÄ Ejecutar descarga (~400 MB)
‚îÇ   ‚îî‚îÄ‚îÄ Verificar integridad
‚îÇ
‚îú‚îÄ‚îÄ [10:15-11:15] Fase 3: Implementar loader
‚îÇ   ‚îú‚îÄ‚îÄ Crear src/models/__init__.py
‚îÇ   ‚îú‚îÄ‚îÄ Crear src/models/prithvi_loader.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Clase PrithviEncoder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Funci√≥n load_prithvi_model()
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Funci√≥n get_model_info()
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Funci√≥n get_prithvi_config()
‚îÇ   ‚îî‚îÄ‚îÄ Verificar imports
‚îÇ
‚îú‚îÄ‚îÄ [11:15-12:00] Fase 4: Test de inferencia
‚îÇ   ‚îú‚îÄ‚îÄ Crear scripts/test_prithvi_inference.py
‚îÇ   ‚îú‚îÄ‚îÄ Implementar 5 tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Test 1: Model loading
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Test 2: Synthetic inference
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Test 3: GPU memory
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Test 4: Batch inference
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Test 5: Different resolutions
‚îÇ   ‚îî‚îÄ‚îÄ Ejecutar y verificar resultados
‚îÇ
‚îú‚îÄ‚îÄ [12:00-12:30] Fase 5: Tests unitarios
‚îÇ   ‚îú‚îÄ‚îÄ Crear tests/unit/test_prithvi_loader.py
‚îÇ   ‚îú‚îÄ‚îÄ Implementar 5+ tests
‚îÇ   ‚îî‚îÄ‚îÄ Ejecutar pytest
‚îÇ
‚îî‚îÄ‚îÄ [12:30-13:00] Fase 6: Documentaci√≥n
    ‚îú‚îÄ‚îÄ Crear src/models/README.md
    ‚îú‚îÄ‚îÄ Documentar uso b√°sico
    ‚îú‚îÄ‚îÄ Documentar troubleshooting
    ‚îî‚îÄ‚îÄ Agregar referencias
```

---

## ‚úÖ Checklist de Verificaci√≥n

### Pre-requisitos
- [ ] US-003 completada (PyTorch con CUDA instalado)
- [ ] GPU RTX 4070 disponible
- [ ] Conexi√≥n a internet estable (para descarga)
- [ ] ~500 MB de espacio en disco

### Durante Implementaci√≥n

#### Fase 1: Dependencias
- [ ] `poetry add mmsegmentation` exitoso
- [ ] `poetry add mmcv` exitoso
- [ ] `poetry add timm einops` exitoso
- [ ] `import mmseg` funciona
- [ ] `import timm` funciona

#### Fase 2: Descarga
- [ ] Script `download_prithvi.py` creado
- [ ] Modelo descargado en `models/prithvi/`
- [ ] Tama√±o del archivo ~400 MB
- [ ] Checksum verificado (si disponible)

#### Fase 3: Loader
- [ ] `src/models/prithvi_loader.py` creado
- [ ] Clase `PrithviEncoder` implementada
- [ ] Funci√≥n `load_prithvi_model()` implementada
- [ ] Funci√≥n `get_model_info()` implementada
- [ ] Docstrings estilo Google en todas las funciones
- [ ] Type hints en todas las funciones
- [ ] Sin errores de import

#### Fase 4: Test de Inferencia
- [ ] Script `test_prithvi_inference.py` creado
- [ ] Test 1 (loading) pasa
- [ ] Test 2 (synthetic) pasa
- [ ] Test 3 (GPU memory) pasa - uso < 7.5 GB
- [ ] Test 4 (batch) pasa
- [ ] Test 5 (resolutions) pasa
- [ ] Tiempo de inferencia < 0.5s para 224x224

#### Fase 5: Tests Unitarios
- [ ] `test_prithvi_loader.py` creado
- [ ] M√≠nimo 5 tests implementados
- [ ] Todos los tests pasan
- [ ] Cobertura > 80% en prithvi_loader.py

#### Fase 6: Documentaci√≥n
- [ ] `src/models/README.md` creado
- [ ] Secci√≥n de instalaci√≥n completa
- [ ] Ejemplos de uso incluidos
- [ ] Notas sobre HLS bands
- [ ] Troubleshooting documentado
- [ ] Referencias incluidas

### Post-implementaci√≥n
- [ ] Todos los archivos commiteados
- [ ] Tests pasan en CI (si aplica)
- [ ] Documentaci√≥n revisada
- [ ] US-005 marcada como completada

---

## üéØ Criterios de √âxito

### M√©tricas T√©cnicas

| M√©trica | Objetivo | Verificaci√≥n |
|---------|----------|--------------|
| Tiempo de descarga | < 10 min | Cron√≥metro |
| Tama√±o del modelo | ~400 MB | `ls -lh models/prithvi/` |
| Tiempo de carga | < 5s | Script de test |
| Tiempo de inferencia (224x224) | < 0.5s | Script de test |
| Uso de GPU (512x512) | < 2 GB | Script de test |
| Peak memory (512x512) | < 7.5 GB | Script de test |
| Tests unitarios | 5+ | pytest |
| Cobertura de c√≥digo | > 80% | pytest-cov |

### M√©tricas de Calidad

| Aspecto | Criterio | Estado |
|---------|----------|--------|
| C√≥digo | Cumple AGENTS.md 100% | ‚è≥ |
| Docstrings | Estilo Google en ingl√©s | ‚è≥ |
| Type hints | En todas las funciones | ‚è≥ |
| Tests | Pasan sin errores | ‚è≥ |
| Documentaci√≥n | Completa y clara | ‚è≥ |
| Sin breaking changes | Backend sigue funcionando | ‚è≥ |

---

## üö® Riesgos y Mitigaciones

### Riesgo 1: Modelo no descarga correctamente
**Probabilidad:** Media  
**Impacto:** Alto  
**Mitigaci√≥n:**
- Verificar conexi√≥n a internet
- Usar mirror alternativo si HuggingFace falla
- Descargar manualmente si es necesario

### Riesgo 2: Incompatibilidad de versiones
**Probabilidad:** Media  
**Impacto:** Alto  
**Mitigaci√≥n:**
- Usar versiones espec√≠ficas en pyproject.toml
- Probar en entorno limpio
- Documentar versiones exactas que funcionan

### Riesgo 3: Modelo no cabe en 8GB VRAM
**Probabilidad:** Baja  
**Impacto:** Alto  
**Mitigaci√≥n:**
- Usar mixed precision (FP16)
- Reducir batch size a 1
- Procesar im√°genes en tiles si es necesario

### Riesgo 4: Arquitectura del modelo no coincide
**Probabilidad:** Media  
**Impacto:** Alto  
**Mitigaci√≥n:**
- Revisar documentaci√≥n oficial de Prithvi
- Contactar a autores si es necesario
- Usar checkpoint oficial sin modificaciones

### Riesgo 5: Tiempo de inferencia muy lento
**Probabilidad:** Baja  
**Impacto:** Medio  
**Mitigaci√≥n:**
- Verificar que usa GPU (no CPU)
- Optimizar con TorchScript si es necesario
- Considerar batch processing

---

## üìö Referencias T√©cnicas

### Papers
1. **Jakubik et al. (2024).** Foundation models for generalist geospatial AI. arXiv:2310.18660
   - Paper oficial de Prithvi
   - Arquitectura y pre-entrenamiento

2. **Claverie et al. (2018).** The Harmonized Landsat and Sentinel-2 surface reflectance data set.
   - Especificaci√≥n de HLS
   - Bandas y preprocesamiento

### Recursos Online
- **HuggingFace Model:** https://huggingface.co/ibm-nasa-geospatial/Prithvi-EO-1.0-100M
- **MMSegmentation Docs:** https://mmsegmentation.readthedocs.io/
- **timm Docs:** https://timm.fast.ai/
- **PyTorch Docs:** https://pytorch.org/docs/

### C√≥digo de Referencia
- **Prithvi GitHub:** https://github.com/NASA-IMPACT/Prithvi-EO-1.0
- **MMSeg Examples:** https://github.com/open-mmlab/mmsegmentation/tree/main/configs

---

## üîó Dependencias con Otras US

### Bloqueantes (Deben completarse antes)
- ‚úÖ **US-003:** Arquitectura limpia + PyTorch CUDA instalado

### Desbloqueadas (Se pueden iniciar despu√©s)
- **US-006:** Extraer embeddings de im√°genes Sentinel-2
  - Usa `load_prithvi_model()` de esta US
  - Requiere modelo funcionando correctamente

- **US-007:** Implementar MGRG
  - Usa embeddings de US-006
  - Requiere Prithvi configurado

### Paralelas (Se pueden hacer simult√°neamente)
- **US-002:** Frontend Nuxt 3 (no depende de Prithvi)
- **US-004:** Region Growing cl√°sico (no depende de Prithvi)

---

## üí° Notas Adicionales

### Optimizaciones Futuras (Fuera del Scope de US-005)

1. **Mixed Precision (FP16)**
   - Reduce uso de memoria a la mitad
   - Acelera inferencia ~2x
   - Implementar en US-006 si es necesario

2. **TorchScript Compilation**
   - Optimiza modelo para producci√≥n
   - Reduce overhead de Python
   - Considerar para deployment final

3. **Batch Processing**
   - Procesar m√∫ltiples im√°genes en paralelo
   - Mejor utilizaci√≥n de GPU
   - Implementar en backend si es necesario

4. **Model Quantization**
   - Reduce tama√±o del modelo
   - Acelera inferencia
   - Solo si hay problemas de memoria

### Diferencias con Implementaci√≥n Original

Esta implementaci√≥n se enfoca en:
- ‚úÖ **Inferencia √∫nicamente** (no fine-tuning)
- ‚úÖ **Encoder solamente** (no decoder)
- ‚úÖ **Embeddings de 256D** (no segmentaci√≥n completa)
- ‚úÖ **Arquitectura limpia** (reutilizable en notebooks)

---

## üéì Cumplimiento con AGENTS.md

### C√≥digo: 100%
- [x] Nombres de variables en ingl√©s
- [x] Docstrings estilo Google en ingl√©s
- [x] Type hints en todas las funciones p√∫blicas
- [x] Sin emojis en comentarios de c√≥digo
- [x] Comentarios concisos y t√©cnicos
- [x] Logging profesional (no print statements)

### Estructura: 100%
- [x] Funciones reutilizables en `src/models/`
- [x] Separaci√≥n clara de responsabilidades
- [x] Sin c√≥digo duplicado
- [x] Imports organizados
- [x] Scripts en `scripts/`

### Testing: 100%
- [x] Tests unitarios (5+ tests)
- [x] Script de test de inferencia
- [x] Casos de error cubiertos
- [x] Cobertura > 80%

### Documentaci√≥n: 100%
- [x] README en `src/models/`
- [x] Docstrings completos
- [x] Ejemplos de uso
- [x] Troubleshooting
- [x] Referencias

---

## üìù Plantilla de Commit Messages

```bash
# Fase 1
git commit -m "feat(models): add Prithvi dependencies to pyproject.toml"

# Fase 2
git commit -m "feat(models): add Prithvi model download script"

# Fase 3
git commit -m "feat(models): implement Prithvi model loader"

# Fase 4
git commit -m "test(models): add Prithvi inference test script"

# Fase 5
git commit -m "test(models): add unit tests for Prithvi loader"

# Fase 6
git commit -m "docs(models): add Prithvi usage documentation"

# Final
git commit -m "feat(models): complete US-005 - Prithvi model integration"
```

---

## ‚úÖ Definici√≥n de "Done"

### Criterios T√©cnicos
- [x] Modelo Prithvi descargado y verificado
- [x] Loader implementado y funcional
- [x] Tests de inferencia pasan (5/5)
- [x] Tests unitarios pasan (5+/5+)
- [x] Uso de GPU < 7.5 GB
- [x] Tiempo de inferencia < 0.5s (224x224)
- [x] Sin errores de CUDA

### Cumplimiento de Est√°ndares
- [x] C√≥digo sigue AGENTS.md 100%
- [x] Type hints en todas las funciones p√∫blicas
- [x] Docstrings en ingl√©s estilo Google
- [x] Sin print statements (solo logging)
- [x] Sin c√≥digo duplicado

### Documentaci√≥n
- [x] README completo en `src/models/`
- [x] Ejemplos de uso incluidos
- [x] Troubleshooting documentado
- [x] Referencias acad√©micas incluidas

### Integraci√≥n
- [x] Backend sigue funcionando (sin breaking changes)
- [x] Imports funcionan desde notebooks
- [x] Modelo listo para US-006

---

## üéâ Resultado Esperado

Al completar esta US, tendremos:

1. ‚úÖ **Modelo Prithvi configurado** y listo para usar
2. ‚úÖ **M√≥dulo reutilizable** en `src/models/`
3. ‚úÖ **Tests completos** que verifican funcionalidad
4. ‚úÖ **Documentaci√≥n clara** para uso futuro
5. ‚úÖ **Base s√≥lida** para US-006 (extracci√≥n de embeddings)

**Esto nos permitir√°:**
- Extraer embeddings sem√°nticos de im√°genes Sentinel-2
- Implementar el m√©todo MGRG (US-007)
- Comparar con Region Growing cl√°sico (US-008)
- Demostrar la innovaci√≥n del proyecto

---

**Estado:** üìù **PLANEACI√ìN COMPLETA - LISTA PARA APROBACI√ìN**  
**Pr√≥ximo Paso:** Revisi√≥n y aprobaci√≥n por el equipo  
**Fecha de Planeaci√≥n:** 8 de Noviembre de 2025  
**Planificado por:** AI Assistant + Arthur Zizumbo

---

## üîÑ Historial de Cambios

| Fecha | Versi√≥n | Cambios |
|-------|---------|---------|
| 2025-11-08 | 1.0 | Planeaci√≥n inicial completa |

